{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies in CpE 2\n",
        "1st Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**Hands-on Activity 6.2** | Training Neural Networks\n",
        "**Name** | Abad, Julia Marie Iberet\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | March 27, 2024\n",
        "**Date Submitted**: | April 2, 2024\n",
        "**Instructor**: | Engr. Roman Richard\n",
        "\n"
      ],
      "metadata": {
        "id": "1kS8lJSFH-uJ"
      },
      "id": "1kS8lJSFH-uJ"
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "undefined-inventory",
        "outputId": "848df3d4-44b6-4737-e1cd-e6b124c04c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "672              10                      68             106              23   \n",
              "148               5                     147              78               0   \n",
              "401               6                     137              61               0   \n",
              "457               5                      86              68              28   \n",
              "99                1                     122              90              51   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "672       49  35.5              0.285   47             0  \n",
              "148        0  33.7              0.218   65             0  \n",
              "401        0  24.2              0.151   55             0  \n",
              "457       71  30.2              0.364   24             0  \n",
              "99       220  49.7              0.325   31             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc78e20e-c063-4bbc-a5cb-316cfa7cab2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>10</td>\n",
              "      <td>68</td>\n",
              "      <td>106</td>\n",
              "      <td>23</td>\n",
              "      <td>49</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.285</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>5</td>\n",
              "      <td>147</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>0.218</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>6</td>\n",
              "      <td>137</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.2</td>\n",
              "      <td>0.151</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>5</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>28</td>\n",
              "      <td>71</td>\n",
              "      <td>30.2</td>\n",
              "      <td>0.364</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>122</td>\n",
              "      <td>90</td>\n",
              "      <td>51</td>\n",
              "      <td>220</td>\n",
              "      <td>49.7</td>\n",
              "      <td>0.325</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc78e20e-c063-4bbc-a5cb-316cfa7cab2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc78e20e-c063-4bbc-a5cb-316cfa7cab2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc78e20e-c063-4bbc-a5cb-316cfa7cab2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c228f530-8cf6-480f-b592-a3939e75a4cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c228f530-8cf6-480f-b592-a3939e75a4cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c228f530-8cf6-480f-b592-a3939e75a4cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          1,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 68,\n        \"max\": 147,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          147,\n          122,\n          137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 61,\n        \"max\": 106,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          78,\n          90,\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 0,\n        \"max\": 51,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          51,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 90,\n        \"min\": 0,\n        \"max\": 220,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          220,\n          49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.448968197639362,\n        \"min\": 24.2,\n        \"max\": 49.7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          33.7,\n          49.7,\n          24.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08506056665694156,\n        \"min\": 0.151,\n        \"max\": 0.364,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.218,\n          0.325,\n          0.151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 24,\n        \"max\": 65,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          65,\n          31,\n          55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "898181a1-de60-419c-f4d9-118e16157257"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "350a21db-0ba5-4e91-f5cf-c390e09df78a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "c4f1b392-c6d5-4808-f581-ee884e21185a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "8a434a43-fcf0-4ca6-c3e5-cddc78ebbe81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 25ms/step - loss: 0.7135 - accuracy: 0.5833 - val_loss: 0.6887 - val_accuracy: 0.5677\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6899 - accuracy: 0.6042 - val_loss: 0.6702 - val_accuracy: 0.5990\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6705 - accuracy: 0.6215 - val_loss: 0.6552 - val_accuracy: 0.6042\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6302 - val_loss: 0.6427 - val_accuracy: 0.5990\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.6389 - val_loss: 0.6322 - val_accuracy: 0.6198\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6476 - val_loss: 0.6233 - val_accuracy: 0.6250\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.6545 - val_loss: 0.6155 - val_accuracy: 0.6458\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.6667 - val_loss: 0.6087 - val_accuracy: 0.6458\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6037 - accuracy: 0.6649 - val_loss: 0.6026 - val_accuracy: 0.6458\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5971 - accuracy: 0.6719 - val_loss: 0.5972 - val_accuracy: 0.6562\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.6823 - val_loss: 0.5924 - val_accuracy: 0.6667\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.6892 - val_loss: 0.5879 - val_accuracy: 0.6719\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6927 - val_loss: 0.5839 - val_accuracy: 0.6771\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6910 - val_loss: 0.5801 - val_accuracy: 0.6823\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6927 - val_loss: 0.5766 - val_accuracy: 0.6875\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.6979 - val_loss: 0.5734 - val_accuracy: 0.6823\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6979 - val_loss: 0.5704 - val_accuracy: 0.6979\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.6979 - val_loss: 0.5676 - val_accuracy: 0.6979\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6962 - val_loss: 0.5649 - val_accuracy: 0.7031\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.6997 - val_loss: 0.5624 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7031 - val_loss: 0.5600 - val_accuracy: 0.7031\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7014 - val_loss: 0.5576 - val_accuracy: 0.7135\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7101 - val_loss: 0.5554 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7101 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7135 - val_loss: 0.5512 - val_accuracy: 0.7188\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.7153 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7170 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7222 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7240 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7257 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7240 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7222 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7257 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7257 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7292 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7326 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7326 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7326 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7361 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7378 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7378 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7413 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7431 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.7465 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7500 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7587 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7569 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7587 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7604 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7604 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7639 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7691 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7708 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7795 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7899 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7882 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7899 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7934 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7969 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7969 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7986 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8021 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8021 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8038 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8021 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8056 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8056 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.8056 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8056 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8056 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8056 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8038 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8038 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8003 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8056 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8038 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8021 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8003 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8003 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8003 - val_loss: 0.4998 - val_accuracy: 0.7812\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7812\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.5000 - val_accuracy: 0.7812\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5000 - val_accuracy: 0.7812\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7812\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7708\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1  = model.predict(X_test_norm)\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Lw25T3UjNE",
        "outputId": "b44fba9a-4f3e-42a9-e0af-88a2a7b1394d"
      },
      "id": "p1Lw25T3UjNE",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "f1195659-0634-4931-c762-f3c7bd0beb74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5899968 ],\n",
              "       [0.59497625],\n",
              "       [0.2839389 ],\n",
              "       [0.2449466 ],\n",
              "       [0.18373224],\n",
              "       [0.5573158 ],\n",
              "       [0.01957704],\n",
              "       [0.3452066 ],\n",
              "       [0.9296316 ],\n",
              "       [0.11585666]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "d494531c-9f96-4fc9-a0ab-a349c7cfad23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5899968 ],\n",
              "       [0.59497625],\n",
              "       [0.2839389 ],\n",
              "       [0.2449466 ],\n",
              "       [0.18373224],\n",
              "       [0.5573158 ],\n",
              "       [0.01957704],\n",
              "       [0.3452066 ],\n",
              "       [0.9296316 ],\n",
              "       [0.11585666]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rf = RandomForestClassifier(n_estimators=200)\n",
        "Rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "2OqKgpdhZtD5",
        "outputId": "27f9d5e6-7f37-449c-9958-eeaab2a6e12c"
      },
      "id": "2OqKgpdhZtD5",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "eleven-nebraska",
        "outputId": "f6f6f588-f6ab-4fdb-8d59-bc8e765f1f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.833\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,Rf.predict(X_test))))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,Rf.predict_proba(X_test)[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "0168cc64-84c5-4f60-92ab-aa9d40f1731d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "118914fa-3770-4209-c740-42af6d566858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x782d17f4ad70>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss? <br>\n",
        "Based on the result, the model is learning and improving initially but eventually reaches a point where additional training epochs don't lead to significant improvements on the validation set. In that case, we can say that the data is underfitting because the train loss and the validation loss fails to reach and match each other."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with 6 nodes:\n",
        "#Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "model_1 = Sequential([\n",
        "    Dense(6, input_shape = (8,), activation = \"sigmoid\"),\n",
        "    Dense(2, activation = \"relu\")\n",
        "])"
      ],
      "metadata": {
        "id": "J_15o7sgajLj"
      },
      "id": "J_15o7sgajLj",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a learning rate of .003 and train for 1500 epochs\n",
        "model_1.compile(SGD(learning_rate = .003), \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "run_his_1 = model_1.fit(X_train_norm, y_train, validation_data = (X_test_norm, y_test), epochs = 1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdlj-K5NbVpJ",
        "outputId": "036f1eb6-0ec2-4f2f-bcc1-cd6ffd62595a"
      },
      "id": "mdlj-K5NbVpJ",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 1.5499 - accuracy: 0.3837 - val_loss: 1.3831 - val_accuracy: 0.3854\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.3605 - accuracy: 0.4149 - val_loss: 1.2652 - val_accuracy: 0.3750\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 3.3237 - accuracy: 0.4306 - val_loss: 1.3000 - val_accuracy: 0.5573\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4127 - accuracy: 0.5556 - val_loss: 1.2868 - val_accuracy: 0.5521\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4191 - accuracy: 0.5521 - val_loss: 1.3776 - val_accuracy: 0.5677\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.3940 - accuracy: 0.5590 - val_loss: 1.2832 - val_accuracy: 0.5677\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.3866 - accuracy: 0.5677 - val_loss: 1.3368 - val_accuracy: 0.5677\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.3629 - accuracy: 0.5573 - val_loss: 1.2401 - val_accuracy: 0.5677\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.3476 - accuracy: 0.5521 - val_loss: 1.2331 - val_accuracy: 0.5625\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.2443 - accuracy: 0.5295 - val_loss: 1.1907 - val_accuracy: 0.5104\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0848 - accuracy: 0.4913 - val_loss: 1.1108 - val_accuracy: 0.4948\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0513 - accuracy: 0.4948 - val_loss: 1.0977 - val_accuracy: 0.4948\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0182 - accuracy: 0.5000 - val_loss: 1.0930 - val_accuracy: 0.5000\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9625 - accuracy: 0.5000 - val_loss: 0.9979 - val_accuracy: 0.4844\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.8861 - accuracy: 0.4757 - val_loss: 0.9049 - val_accuracy: 0.5000\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8612 - accuracy: 0.4878 - val_loss: 0.8705 - val_accuracy: 0.5156\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8603 - accuracy: 0.4913 - val_loss: 0.8532 - val_accuracy: 0.5000\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.7994 - accuracy: 0.4861 - val_loss: 0.8432 - val_accuracy: 0.5104\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7822 - accuracy: 0.4861 - val_loss: 0.8354 - val_accuracy: 0.5156\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7719 - accuracy: 0.4983 - val_loss: 0.8320 - val_accuracy: 0.5260\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.5087 - val_loss: 0.8287 - val_accuracy: 0.5052\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8419 - accuracy: 0.5139 - val_loss: 1.4200 - val_accuracy: 0.6302\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.3314 - accuracy: 0.6163 - val_loss: 1.1315 - val_accuracy: 0.5990\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9382 - accuracy: 0.5538 - val_loss: 0.8470 - val_accuracy: 0.5573\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5052 - val_loss: 0.7526 - val_accuracy: 0.5156\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6576 - accuracy: 0.4948 - val_loss: 0.6764 - val_accuracy: 0.4844\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.4774 - val_loss: 0.6735 - val_accuracy: 0.4740\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.4774 - val_loss: 0.6714 - val_accuracy: 0.4740\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.4792 - val_loss: 0.6690 - val_accuracy: 0.4792\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.4826 - val_loss: 0.6670 - val_accuracy: 0.4740\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.4826 - val_loss: 0.6649 - val_accuracy: 0.4740\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.4826 - val_loss: 0.6618 - val_accuracy: 0.4740\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.4826 - val_loss: 0.6594 - val_accuracy: 0.4792\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.4757 - val_loss: 0.6573 - val_accuracy: 0.4792\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.4774 - val_loss: 0.6551 - val_accuracy: 0.4792\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.4809 - val_loss: 0.6536 - val_accuracy: 0.4792\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.4809 - val_loss: 0.6518 - val_accuracy: 0.4792\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6048 - accuracy: 0.4826 - val_loss: 0.6500 - val_accuracy: 0.4792\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.4809 - val_loss: 0.6485 - val_accuracy: 0.4792\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6006 - accuracy: 0.4826 - val_loss: 0.6473 - val_accuracy: 0.4792\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.4809 - val_loss: 0.6458 - val_accuracy: 0.4792\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.4826 - val_loss: 0.6447 - val_accuracy: 0.4792\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.4826 - val_loss: 0.6434 - val_accuracy: 0.4792\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5930 - accuracy: 0.4826 - val_loss: 0.6428 - val_accuracy: 0.4948\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.4861 - val_loss: 0.6416 - val_accuracy: 0.4948\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.5898 - accuracy: 0.4861 - val_loss: 0.6411 - val_accuracy: 0.4948\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5879 - accuracy: 0.4861 - val_loss: 0.6411 - val_accuracy: 0.4948\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.5861 - accuracy: 0.4896 - val_loss: 0.6402 - val_accuracy: 0.4896\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.4878 - val_loss: 0.6637 - val_accuracy: 0.4896\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5832 - accuracy: 0.4878 - val_loss: 0.6455 - val_accuracy: 0.4896\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5816 - accuracy: 0.4878 - val_loss: 0.6611 - val_accuracy: 0.4844\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.4861 - val_loss: 0.6600 - val_accuracy: 0.4844\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5787 - accuracy: 0.4878 - val_loss: 0.6590 - val_accuracy: 0.4844\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5772 - accuracy: 0.4913 - val_loss: 0.6578 - val_accuracy: 0.4844\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.4878 - val_loss: 0.6568 - val_accuracy: 0.4948\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5745 - accuracy: 0.4896 - val_loss: 0.6560 - val_accuracy: 0.5000\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.4931 - val_loss: 0.6559 - val_accuracy: 0.5000\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5718 - accuracy: 0.4931 - val_loss: 0.6562 - val_accuracy: 0.5000\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.4913 - val_loss: 0.6584 - val_accuracy: 0.5104\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5694 - accuracy: 0.4931 - val_loss: 0.6782 - val_accuracy: 0.5104\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.5682 - accuracy: 0.4913 - val_loss: 0.6770 - val_accuracy: 0.5104\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5668 - accuracy: 0.4983 - val_loss: 0.6759 - val_accuracy: 0.5104\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5657 - accuracy: 0.4983 - val_loss: 0.6749 - val_accuracy: 0.5104\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5643 - accuracy: 0.5000 - val_loss: 0.6739 - val_accuracy: 0.5104\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5546 - accuracy: 0.4913 - val_loss: 0.6730 - val_accuracy: 0.4792\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5517 - accuracy: 0.4878 - val_loss: 0.6717 - val_accuracy: 0.4948\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5503 - accuracy: 0.4965 - val_loss: 0.6705 - val_accuracy: 0.5000\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5490 - accuracy: 0.4965 - val_loss: 0.6695 - val_accuracy: 0.5104\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5480 - accuracy: 0.4948 - val_loss: 0.6685 - val_accuracy: 0.5104\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5465 - accuracy: 0.5017 - val_loss: 0.6675 - val_accuracy: 0.5156\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.5017 - val_loss: 0.6666 - val_accuracy: 0.5156\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5443 - accuracy: 0.5035 - val_loss: 0.6657 - val_accuracy: 0.5156\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5434 - accuracy: 0.5052 - val_loss: 0.6649 - val_accuracy: 0.5156\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.5422 - accuracy: 0.5017 - val_loss: 0.6640 - val_accuracy: 0.5208\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.5409 - accuracy: 0.5052 - val_loss: 0.6632 - val_accuracy: 0.5208\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5402 - accuracy: 0.5087 - val_loss: 0.6623 - val_accuracy: 0.5208\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.5035 - val_loss: 0.6615 - val_accuracy: 0.5208\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.5052 - val_loss: 0.6608 - val_accuracy: 0.5208\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.5052 - val_loss: 0.6600 - val_accuracy: 0.5208\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.5104 - val_loss: 0.6593 - val_accuracy: 0.5208\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.5069 - val_loss: 0.6585 - val_accuracy: 0.5208\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.5139 - val_loss: 0.6578 - val_accuracy: 0.5208\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5335 - accuracy: 0.5122 - val_loss: 0.6571 - val_accuracy: 0.5208\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.5122 - val_loss: 0.6564 - val_accuracy: 0.5208\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.5104 - val_loss: 0.6557 - val_accuracy: 0.5208\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.5174 - val_loss: 0.6551 - val_accuracy: 0.5208\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.5156 - val_loss: 0.6544 - val_accuracy: 0.5208\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5292 - accuracy: 0.5156 - val_loss: 0.6538 - val_accuracy: 0.5208\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.5174 - val_loss: 0.6532 - val_accuracy: 0.5260\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.5243 - val_loss: 0.6526 - val_accuracy: 0.5208\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.5191 - val_loss: 0.6520 - val_accuracy: 0.5312\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.5191 - val_loss: 0.6514 - val_accuracy: 0.5312\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.5260 - val_loss: 0.6509 - val_accuracy: 0.5312\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.5278 - val_loss: 0.6503 - val_accuracy: 0.5260\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.5312 - val_loss: 0.6498 - val_accuracy: 0.5260\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.5295 - val_loss: 0.6493 - val_accuracy: 0.5260\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.5278 - val_loss: 0.6488 - val_accuracy: 0.5260\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.5365 - val_loss: 0.6483 - val_accuracy: 0.5260\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.5365 - val_loss: 0.6478 - val_accuracy: 0.5260\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.5330 - val_loss: 0.6473 - val_accuracy: 0.5208\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5201 - accuracy: 0.5365 - val_loss: 0.6469 - val_accuracy: 0.5260\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.5417 - val_loss: 0.6464 - val_accuracy: 0.5260\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.5399 - val_loss: 0.6460 - val_accuracy: 0.5260\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.5434 - val_loss: 0.6455 - val_accuracy: 0.5208\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.5434 - val_loss: 0.6451 - val_accuracy: 0.5260\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.5434 - val_loss: 0.6447 - val_accuracy: 0.5260\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.5486 - val_loss: 0.6443 - val_accuracy: 0.5260\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.5417 - val_loss: 0.6439 - val_accuracy: 0.5312\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.5434 - val_loss: 0.6435 - val_accuracy: 0.5312\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.5486 - val_loss: 0.6431 - val_accuracy: 0.5312\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.5451 - val_loss: 0.6427 - val_accuracy: 0.5365\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.5503 - val_loss: 0.6424 - val_accuracy: 0.5417\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.5486 - val_loss: 0.6420 - val_accuracy: 0.5469\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.5503 - val_loss: 0.6417 - val_accuracy: 0.5469\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.5486 - val_loss: 0.6414 - val_accuracy: 0.5469\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.5503 - val_loss: 0.6411 - val_accuracy: 0.5469\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.5521 - val_loss: 0.6408 - val_accuracy: 0.5469\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5112 - accuracy: 0.5486 - val_loss: 0.6405 - val_accuracy: 0.5469\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.5538 - val_loss: 0.6402 - val_accuracy: 0.5469\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.5469 - val_loss: 0.6399 - val_accuracy: 0.5469\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.5538 - val_loss: 0.6396 - val_accuracy: 0.5469\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.5573 - val_loss: 0.6394 - val_accuracy: 0.5469\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.5573 - val_loss: 0.6391 - val_accuracy: 0.5469\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.5573 - val_loss: 0.6388 - val_accuracy: 0.5469\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.5538 - val_loss: 0.6386 - val_accuracy: 0.5469\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.5538 - val_loss: 0.6386 - val_accuracy: 0.5521\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5073 - accuracy: 0.5556 - val_loss: 0.6384 - val_accuracy: 0.5521\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.5573 - val_loss: 0.6380 - val_accuracy: 0.5521\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.5590 - val_loss: 0.6378 - val_accuracy: 0.5521\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.5538 - val_loss: 0.6378 - val_accuracy: 0.5521\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.5573 - val_loss: 0.6376 - val_accuracy: 0.5521\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.5573 - val_loss: 0.6374 - val_accuracy: 0.5521\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.5556 - val_loss: 0.6370 - val_accuracy: 0.5625\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.5590 - val_loss: 0.6370 - val_accuracy: 0.5625\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.5573 - val_loss: 0.6367 - val_accuracy: 0.5625\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.5590 - val_loss: 0.6367 - val_accuracy: 0.5625\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.5608 - val_loss: 0.6367 - val_accuracy: 0.5625\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.5642 - val_loss: 0.6365 - val_accuracy: 0.5625\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.5590 - val_loss: 0.6365 - val_accuracy: 0.5625\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.5642 - val_loss: 0.6360 - val_accuracy: 0.5625\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.5590 - val_loss: 0.6359 - val_accuracy: 0.5677\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.5625 - val_loss: 0.6359 - val_accuracy: 0.5677\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.5608 - val_loss: 0.6358 - val_accuracy: 0.5625\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.5625 - val_loss: 0.6359 - val_accuracy: 0.5729\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.5590 - val_loss: 0.6359 - val_accuracy: 0.5677\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.5729 - val_loss: 0.6358 - val_accuracy: 0.5729\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.5694 - val_loss: 0.6126 - val_accuracy: 0.5729\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.5660 - val_loss: 0.6121 - val_accuracy: 0.5729\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.5677 - val_loss: 0.6111 - val_accuracy: 0.5729\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.5677 - val_loss: 0.6099 - val_accuracy: 0.5781\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.5694 - val_loss: 0.6098 - val_accuracy: 0.5781\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.5642 - val_loss: 0.6096 - val_accuracy: 0.5781\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.5712 - val_loss: 0.6081 - val_accuracy: 0.5833\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.5677 - val_loss: 0.6095 - val_accuracy: 0.5781\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.5729 - val_loss: 0.6102 - val_accuracy: 0.5833\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.5712 - val_loss: 0.6089 - val_accuracy: 0.5781\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.5660 - val_loss: 0.6092 - val_accuracy: 0.5781\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.5712 - val_loss: 0.6094 - val_accuracy: 0.5781\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.5781 - val_loss: 0.6077 - val_accuracy: 0.5781\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.5712 - val_loss: 0.6081 - val_accuracy: 0.5781\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.5764 - val_loss: 0.6097 - val_accuracy: 0.5781\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4966 - accuracy: 0.5764 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4960 - accuracy: 0.5729 - val_loss: 0.6111 - val_accuracy: 0.5938\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4961 - accuracy: 0.5833 - val_loss: 0.6302 - val_accuracy: 0.5885\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4956 - accuracy: 0.5712 - val_loss: 0.6084 - val_accuracy: 0.5938\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4953 - accuracy: 0.5764 - val_loss: 0.6296 - val_accuracy: 0.5938\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4953 - accuracy: 0.5781 - val_loss: 0.6293 - val_accuracy: 0.5938\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4952 - accuracy: 0.5816 - val_loss: 0.6293 - val_accuracy: 0.5938\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4946 - accuracy: 0.5799 - val_loss: 0.6290 - val_accuracy: 0.5938\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4945 - accuracy: 0.5781 - val_loss: 0.6126 - val_accuracy: 0.5938\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4943 - accuracy: 0.5764 - val_loss: 0.6284 - val_accuracy: 0.5990\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.5851 - val_loss: 0.6281 - val_accuracy: 0.5990\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4939 - accuracy: 0.5799 - val_loss: 0.6280 - val_accuracy: 0.6042\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4934 - accuracy: 0.5799 - val_loss: 0.6278 - val_accuracy: 0.6042\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4934 - accuracy: 0.5851 - val_loss: 0.6276 - val_accuracy: 0.6094\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.5816 - val_loss: 0.6274 - val_accuracy: 0.6094\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.5816 - val_loss: 0.6271 - val_accuracy: 0.6094\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.5816 - val_loss: 0.6270 - val_accuracy: 0.6094\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.5816 - val_loss: 0.6267 - val_accuracy: 0.6146\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.5816 - val_loss: 0.6266 - val_accuracy: 0.6146\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.5799 - val_loss: 0.6265 - val_accuracy: 0.6094\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.5799 - val_loss: 0.6264 - val_accuracy: 0.6094\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.5851 - val_loss: 0.6263 - val_accuracy: 0.6042\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.5885 - val_loss: 0.6259 - val_accuracy: 0.6146\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.5851 - val_loss: 0.6257 - val_accuracy: 0.6146\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.5833 - val_loss: 0.6255 - val_accuracy: 0.6094\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.5833 - val_loss: 0.6254 - val_accuracy: 0.6198\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.5851 - val_loss: 0.6254 - val_accuracy: 0.6198\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.5885 - val_loss: 0.6252 - val_accuracy: 0.6250\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.5868 - val_loss: 0.6250 - val_accuracy: 0.6250\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.5816 - val_loss: 0.6249 - val_accuracy: 0.6198\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.5868 - val_loss: 0.6247 - val_accuracy: 0.6250\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.5851 - val_loss: 0.6247 - val_accuracy: 0.6198\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.5851 - val_loss: 0.6245 - val_accuracy: 0.6198\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.5833 - val_loss: 0.6244 - val_accuracy: 0.6198\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.5851 - val_loss: 0.6243 - val_accuracy: 0.6198\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.5920 - val_loss: 0.6241 - val_accuracy: 0.6198\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.5868 - val_loss: 0.6240 - val_accuracy: 0.6198\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.5903 - val_loss: 0.6239 - val_accuracy: 0.6198\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.5868 - val_loss: 0.6240 - val_accuracy: 0.6198\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.5920 - val_loss: 0.6239 - val_accuracy: 0.6198\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.5938 - val_loss: 0.6236 - val_accuracy: 0.6198\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.5885 - val_loss: 0.6238 - val_accuracy: 0.6198\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.5868 - val_loss: 0.6235 - val_accuracy: 0.6198\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.5938 - val_loss: 0.6231 - val_accuracy: 0.6198\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.5972 - val_loss: 0.6230 - val_accuracy: 0.6198\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.5851 - val_loss: 0.6232 - val_accuracy: 0.6198\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.5903 - val_loss: 0.6229 - val_accuracy: 0.6198\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.5955 - val_loss: 0.6229 - val_accuracy: 0.6198\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.5868 - val_loss: 0.6230 - val_accuracy: 0.6198\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.5938 - val_loss: 0.6227 - val_accuracy: 0.6198\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.5903 - val_loss: 0.6228 - val_accuracy: 0.6198\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.5955 - val_loss: 0.6228 - val_accuracy: 0.6198\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.5920 - val_loss: 0.6227 - val_accuracy: 0.6198\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.5903 - val_loss: 0.6227 - val_accuracy: 0.6198\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.5903 - val_loss: 0.6228 - val_accuracy: 0.6198\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.5938 - val_loss: 0.6225 - val_accuracy: 0.6198\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.5903 - val_loss: 0.6225 - val_accuracy: 0.6198\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.5920 - val_loss: 0.6221 - val_accuracy: 0.6198\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.5903 - val_loss: 0.6222 - val_accuracy: 0.6198\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.5903 - val_loss: 0.6222 - val_accuracy: 0.6198\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.5938 - val_loss: 0.6220 - val_accuracy: 0.6198\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.5938 - val_loss: 0.6219 - val_accuracy: 0.6198\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.5868 - val_loss: 0.6221 - val_accuracy: 0.6198\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.5868 - val_loss: 0.6219 - val_accuracy: 0.6198\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.5903 - val_loss: 0.6217 - val_accuracy: 0.6198\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.5920 - val_loss: 0.6219 - val_accuracy: 0.6198\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.5920 - val_loss: 0.6220 - val_accuracy: 0.6198\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.5920 - val_loss: 0.6219 - val_accuracy: 0.6198\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.5955 - val_loss: 0.6218 - val_accuracy: 0.6198\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.5903 - val_loss: 0.6215 - val_accuracy: 0.6198\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.5903 - val_loss: 0.6218 - val_accuracy: 0.6198\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.5938 - val_loss: 0.6216 - val_accuracy: 0.6198\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.5955 - val_loss: 0.6218 - val_accuracy: 0.6198\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.5920 - val_loss: 0.6215 - val_accuracy: 0.6198\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.5885 - val_loss: 0.6212 - val_accuracy: 0.6198\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.5851 - val_loss: 0.6214 - val_accuracy: 0.6198\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.5885 - val_loss: 0.6213 - val_accuracy: 0.6198\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.5868 - val_loss: 0.6213 - val_accuracy: 0.6198\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.5955 - val_loss: 0.6212 - val_accuracy: 0.6198\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.5920 - val_loss: 0.6211 - val_accuracy: 0.6198\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.5903 - val_loss: 0.6211 - val_accuracy: 0.6250\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.5920 - val_loss: 0.6213 - val_accuracy: 0.6198\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.5920 - val_loss: 0.6214 - val_accuracy: 0.6198\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.5903 - val_loss: 0.6213 - val_accuracy: 0.6250\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.5920 - val_loss: 0.6216 - val_accuracy: 0.6250\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.5903 - val_loss: 0.6213 - val_accuracy: 0.6198\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.5920 - val_loss: 0.6213 - val_accuracy: 0.6302\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.5955 - val_loss: 0.6212 - val_accuracy: 0.6302\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.5903 - val_loss: 0.6210 - val_accuracy: 0.6302\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.5938 - val_loss: 0.6209 - val_accuracy: 0.6302\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.5903 - val_loss: 0.6206 - val_accuracy: 0.6302\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.5903 - val_loss: 0.6204 - val_accuracy: 0.6302\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.5885 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.5920 - val_loss: 0.6206 - val_accuracy: 0.6250\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.5955 - val_loss: 0.6204 - val_accuracy: 0.6250\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.5903 - val_loss: 0.6203 - val_accuracy: 0.6250\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.5920 - val_loss: 0.6202 - val_accuracy: 0.6302\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.5868 - val_loss: 0.6206 - val_accuracy: 0.6302\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4820 - accuracy: 0.5955 - val_loss: 0.6207 - val_accuracy: 0.6250\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4819 - accuracy: 0.5885 - val_loss: 0.6207 - val_accuracy: 0.6250\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4820 - accuracy: 0.5920 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4818 - accuracy: 0.5903 - val_loss: 0.6204 - val_accuracy: 0.6250\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4817 - accuracy: 0.5885 - val_loss: 0.6210 - val_accuracy: 0.6250\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4819 - accuracy: 0.5955 - val_loss: 0.6211 - val_accuracy: 0.6250\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4815 - accuracy: 0.5938 - val_loss: 0.6206 - val_accuracy: 0.6302\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4816 - accuracy: 0.5903 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4815 - accuracy: 0.5955 - val_loss: 0.6204 - val_accuracy: 0.6302\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.5920 - val_loss: 0.6205 - val_accuracy: 0.6302\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4811 - accuracy: 0.5920 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.5938 - val_loss: 0.6207 - val_accuracy: 0.6302\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4812 - accuracy: 0.5903 - val_loss: 0.6204 - val_accuracy: 0.6250\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.5920 - val_loss: 0.6204 - val_accuracy: 0.6302\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4808 - accuracy: 0.5868 - val_loss: 0.6206 - val_accuracy: 0.6250\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4810 - accuracy: 0.5920 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.6024 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.5955 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.5885 - val_loss: 0.6207 - val_accuracy: 0.6302\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.5903 - val_loss: 0.6212 - val_accuracy: 0.6250\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.5938 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.5955 - val_loss: 0.6204 - val_accuracy: 0.6250\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.5920 - val_loss: 0.6207 - val_accuracy: 0.6250\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.5955 - val_loss: 0.6210 - val_accuracy: 0.6354\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.5955 - val_loss: 0.6208 - val_accuracy: 0.6354\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.5885 - val_loss: 0.6206 - val_accuracy: 0.6250\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.5955 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.5938 - val_loss: 0.6209 - val_accuracy: 0.6354\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.5972 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.5920 - val_loss: 0.6211 - val_accuracy: 0.6250\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.5972 - val_loss: 0.6214 - val_accuracy: 0.6250\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.5990 - val_loss: 0.6211 - val_accuracy: 0.6354\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.5938 - val_loss: 0.6216 - val_accuracy: 0.6354\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.5955 - val_loss: 0.6213 - val_accuracy: 0.6250\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.5990 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.5972 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.5955 - val_loss: 0.6211 - val_accuracy: 0.6250\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.5955 - val_loss: 0.6213 - val_accuracy: 0.6250\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4796 - accuracy: 0.5938 - val_loss: 0.6218 - val_accuracy: 0.6250\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.5938 - val_loss: 0.6219 - val_accuracy: 0.6250\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.6007 - val_loss: 0.6216 - val_accuracy: 0.6406\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.5955 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.5972 - val_loss: 0.6215 - val_accuracy: 0.6406\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.5990 - val_loss: 0.6214 - val_accuracy: 0.6302\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.5972 - val_loss: 0.6212 - val_accuracy: 0.6354\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.5990 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.5955 - val_loss: 0.6211 - val_accuracy: 0.6250\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.5955 - val_loss: 0.6212 - val_accuracy: 0.6250\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.5972 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.5990 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.5972 - val_loss: 0.6208 - val_accuracy: 0.6250\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.5972 - val_loss: 0.6216 - val_accuracy: 0.6250\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.5938 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.5955 - val_loss: 0.6216 - val_accuracy: 0.6250\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.5972 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.5938 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.5955 - val_loss: 0.6226 - val_accuracy: 0.6302\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.6007 - val_loss: 0.6212 - val_accuracy: 0.6302\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.5938 - val_loss: 0.6218 - val_accuracy: 0.6250\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.5955 - val_loss: 0.6220 - val_accuracy: 0.6250\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.5955 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.6024 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.5955 - val_loss: 0.6218 - val_accuracy: 0.6250\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.5955 - val_loss: 0.6219 - val_accuracy: 0.6302\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.5972 - val_loss: 0.6227 - val_accuracy: 0.6250\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4777 - accuracy: 0.6007 - val_loss: 0.6221 - val_accuracy: 0.6250\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.5972 - val_loss: 0.6219 - val_accuracy: 0.6250\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.5938 - val_loss: 0.6230 - val_accuracy: 0.6250\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.5955 - val_loss: 0.6248 - val_accuracy: 0.6302\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4777 - accuracy: 0.5972 - val_loss: 0.6227 - val_accuracy: 0.6302\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.5920 - val_loss: 0.6230 - val_accuracy: 0.6354\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.5972 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.5938 - val_loss: 0.6244 - val_accuracy: 0.6250\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.5972 - val_loss: 0.6233 - val_accuracy: 0.6250\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.5990 - val_loss: 0.6227 - val_accuracy: 0.6354\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.5990 - val_loss: 0.6245 - val_accuracy: 0.6250\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.5955 - val_loss: 0.6267 - val_accuracy: 0.6250\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.6007 - val_loss: 0.6251 - val_accuracy: 0.6250\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.5990 - val_loss: 0.6491 - val_accuracy: 0.6146\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.6042 - val_loss: 0.6262 - val_accuracy: 0.6198\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.5920 - val_loss: 0.6248 - val_accuracy: 0.6198\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.6007 - val_loss: 0.6258 - val_accuracy: 0.6198\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.5972 - val_loss: 0.6270 - val_accuracy: 0.6198\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.6007 - val_loss: 0.6265 - val_accuracy: 0.6198\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.6024 - val_loss: 0.6263 - val_accuracy: 0.6250\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.5955 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.6042 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.5938 - val_loss: 0.6271 - val_accuracy: 0.6198\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.5972 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.5972 - val_loss: 0.6489 - val_accuracy: 0.6146\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.5990 - val_loss: 0.6490 - val_accuracy: 0.6146\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.5972 - val_loss: 0.6489 - val_accuracy: 0.6146\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6146\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.5990 - val_loss: 0.6489 - val_accuracy: 0.6250\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4767 - accuracy: 0.6024 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6146\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4763 - accuracy: 0.5955 - val_loss: 0.6490 - val_accuracy: 0.6146\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4763 - accuracy: 0.5972 - val_loss: 0.6489 - val_accuracy: 0.6250\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6250\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4761 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4760 - accuracy: 0.5972 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6146\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4759 - accuracy: 0.5990 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.5938 - val_loss: 0.6486 - val_accuracy: 0.6146\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4760 - accuracy: 0.5955 - val_loss: 0.6486 - val_accuracy: 0.6250\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.5972 - val_loss: 0.6486 - val_accuracy: 0.6198\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4760 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6146\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4759 - accuracy: 0.5920 - val_loss: 0.6486 - val_accuracy: 0.6146\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.6007 - val_loss: 0.6486 - val_accuracy: 0.6146\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4759 - accuracy: 0.5972 - val_loss: 0.6487 - val_accuracy: 0.6146\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4759 - accuracy: 0.5990 - val_loss: 0.6484 - val_accuracy: 0.6302\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.5955 - val_loss: 0.6485 - val_accuracy: 0.6198\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6146\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.5955 - val_loss: 0.6483 - val_accuracy: 0.6198\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.5990 - val_loss: 0.6484 - val_accuracy: 0.6302\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.5972 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.5920 - val_loss: 0.6484 - val_accuracy: 0.6354\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.5972 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.5920 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.5938 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.5972 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.6059 - val_loss: 0.6483 - val_accuracy: 0.6302\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4754 - accuracy: 0.5972 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.5955 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.5972 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.5955 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.5955 - val_loss: 0.6481 - val_accuracy: 0.6302\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.5972 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.5955 - val_loss: 0.6480 - val_accuracy: 0.6250\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4750 - accuracy: 0.5920 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.5972 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.5955 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.6042 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.6076 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.5972 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.5990 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.5972 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.6042 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.5972 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.6042 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.6007 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.6094 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.5972 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.6076 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4744 - accuracy: 0.5990 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4742 - accuracy: 0.5990 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6250\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.5990 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.5972 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.6059 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.5990 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.5972 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.5972 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.6007 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.5955 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.5990 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.6059 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.6042 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4736 - accuracy: 0.6059 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4734 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4736 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4733 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4735 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4733 - accuracy: 0.5990 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.6076 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4733 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4734 - accuracy: 0.6076 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.5990 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4733 - accuracy: 0.5972 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4731 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4733 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4732 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4730 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4732 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.6094 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.6059 - val_loss: 0.6482 - val_accuracy: 0.6354\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.6076 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.6076 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.6059 - val_loss: 0.6477 - val_accuracy: 0.6354\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.6042 - val_loss: 0.6477 - val_accuracy: 0.6354\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.5990 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.6007 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.5990 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.6007 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.5972 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.6094 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.5990 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.6007 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.5990 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6458\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.5938 - val_loss: 0.6479 - val_accuracy: 0.6458\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6458\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.5990 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.5955 - val_loss: 0.6476 - val_accuracy: 0.6458\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.6059 - val_loss: 0.6478 - val_accuracy: 0.6458\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4726 - accuracy: 0.6007 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.6024 - val_loss: 0.6476 - val_accuracy: 0.6458\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.6059 - val_loss: 0.6476 - val_accuracy: 0.6354\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.5972 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.5955 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.5990 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.5972 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.6059 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.5972 - val_loss: 0.6479 - val_accuracy: 0.6354\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6354\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.5990 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.6007 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.6024 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.6094 - val_loss: 0.6475 - val_accuracy: 0.6458\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.6007 - val_loss: 0.6475 - val_accuracy: 0.6406\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.6024 - val_loss: 0.6475 - val_accuracy: 0.6406\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.6042 - val_loss: 0.6474 - val_accuracy: 0.6406\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.6007 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.5972 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.5990 - val_loss: 0.6477 - val_accuracy: 0.6458\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.6076 - val_loss: 0.6479 - val_accuracy: 0.6458\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.6059 - val_loss: 0.6479 - val_accuracy: 0.6458\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.6059 - val_loss: 0.6481 - val_accuracy: 0.6458\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6458\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.6076 - val_loss: 0.6477 - val_accuracy: 0.6458\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.6042 - val_loss: 0.6476 - val_accuracy: 0.6458\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6458\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.6059 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4719 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6458\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4719 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6458\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4719 - accuracy: 0.6076 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.5990 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4719 - accuracy: 0.5990 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.6024 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4720 - accuracy: 0.6042 - val_loss: 0.6473 - val_accuracy: 0.6406\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.5990 - val_loss: 0.6474 - val_accuracy: 0.6458\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.5990 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4717 - accuracy: 0.6007 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4718 - accuracy: 0.6007 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4718 - accuracy: 0.6076 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.6076 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4718 - accuracy: 0.6059 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4716 - accuracy: 0.6059 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4717 - accuracy: 0.6076 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.6024 - val_loss: 0.6477 - val_accuracy: 0.6406\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.6042 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.6042 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.6076 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.6042 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.6059 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.6059 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4717 - accuracy: 0.6059 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.6059 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.6076 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.5990 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.6024 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.6042 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.6059 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.6042 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.6007 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.6024 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6076 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.6042 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.6042 - val_loss: 0.6478 - val_accuracy: 0.6458\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6076 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6458\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.6042 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.6059 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6094 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.6042 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.6024 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4709 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4710 - accuracy: 0.6007 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.6076 - val_loss: 0.6485 - val_accuracy: 0.6458\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.6042 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.6059 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6458\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.6024 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.6076 - val_loss: 0.6482 - val_accuracy: 0.6458\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.6042 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.6059 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.6042 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.6059 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.6076 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4710 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6458\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.6059 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.6076 - val_loss: 0.6477 - val_accuracy: 0.6406\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.6076 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4709 - accuracy: 0.6042 - val_loss: 0.6484 - val_accuracy: 0.6458\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4705 - accuracy: 0.6059 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4707 - accuracy: 0.6042 - val_loss: 0.6482 - val_accuracy: 0.6458\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4711 - accuracy: 0.6042 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4708 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4706 - accuracy: 0.6076 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.6076 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.6042 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4706 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4708 - accuracy: 0.6059 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4707 - accuracy: 0.6094 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4707 - accuracy: 0.6076 - val_loss: 0.6486 - val_accuracy: 0.6458\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.6042 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.6024 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4704 - accuracy: 0.6042 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4704 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4706 - accuracy: 0.5972 - val_loss: 0.6488 - val_accuracy: 0.6458\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.6094 - val_loss: 0.6485 - val_accuracy: 0.6458\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6458\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.6042 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4703 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6458\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.6042 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.6059 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.6024 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.6059 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6458\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6458\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.6059 - val_loss: 0.6489 - val_accuracy: 0.6458\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6458\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.6024 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6458\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.6076 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.6094 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4706 - accuracy: 0.6059 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.6059 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4702 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.6076 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.6007 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.6024 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.6007 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.6076 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.6076 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.6007 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.6042 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.6007 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.6007 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.6059 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.6059 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.6042 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.6042 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.5972 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.6042 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.6076 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4700 - accuracy: 0.6059 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.6059 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6458\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.6024 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.6042 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.6094 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6354\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.6007 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.6059 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.6042 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.6042 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.6024 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.6059 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4699 - accuracy: 0.6059 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4700 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4698 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4696 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4697 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4697 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4697 - accuracy: 0.6059 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.5990 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4697 - accuracy: 0.6007 - val_loss: 0.6503 - val_accuracy: 0.6354\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4697 - accuracy: 0.6094 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4699 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 0.6076 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.6076 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4697 - accuracy: 0.6024 - val_loss: 0.6484 - val_accuracy: 0.6354\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4696 - accuracy: 0.6007 - val_loss: 0.6486 - val_accuracy: 0.6354\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4697 - accuracy: 0.5990 - val_loss: 0.6487 - val_accuracy: 0.6354\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.6007 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.6007 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.6042 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.5990 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4697 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.5990 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.6042 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.6024 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4697 - accuracy: 0.6059 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.6007 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4695 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4696 - accuracy: 0.5972 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4696 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4697 - accuracy: 0.6042 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4694 - accuracy: 0.5990 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4693 - accuracy: 0.6059 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.5990 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.6007 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.6076 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.6007 - val_loss: 0.6486 - val_accuracy: 0.6354\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4692 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.5972 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4692 - accuracy: 0.6059 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.5990 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.6042 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.6024 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.6076 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4692 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.6076 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.5990 - val_loss: 0.6497 - val_accuracy: 0.6406\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.6059 - val_loss: 0.6487 - val_accuracy: 0.6354\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.6094 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.5990 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.5955 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.5972 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.5972 - val_loss: 0.6486 - val_accuracy: 0.6354\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.6024 - val_loss: 0.6487 - val_accuracy: 0.6354\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6484 - val_accuracy: 0.6354\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.6007 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.5990 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4691 - accuracy: 0.6024 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.6059 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4690 - accuracy: 0.6024 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4690 - accuracy: 0.5990 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6354\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4689 - accuracy: 0.6059 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.5990 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4693 - accuracy: 0.6007 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4689 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6302\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4688 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4688 - accuracy: 0.5990 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.6007 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4689 - accuracy: 0.6007 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4690 - accuracy: 0.6007 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4690 - accuracy: 0.6042 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6302\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.4689 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6302\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4689 - accuracy: 0.5990 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4690 - accuracy: 0.6059 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4689 - accuracy: 0.6007 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.5972 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.5972 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.6059 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.5972 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6302\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.5990 - val_loss: 0.6486 - val_accuracy: 0.6302\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.5972 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.6007 - val_loss: 0.6497 - val_accuracy: 0.6406\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4687 - accuracy: 0.6007 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.6007 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.6024 - val_loss: 0.6485 - val_accuracy: 0.6302\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.5990 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.6059 - val_loss: 0.6493 - val_accuracy: 0.6302\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.5972 - val_loss: 0.6498 - val_accuracy: 0.6354\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.6007 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.6042 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.5972 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.5990 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4686 - accuracy: 0.6007 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.6059 - val_loss: 0.6494 - val_accuracy: 0.6302\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6490 - val_accuracy: 0.6302\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6302\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.5972 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6495 - val_accuracy: 0.6302\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.6024 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4687 - accuracy: 0.6007 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.6042 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.6024 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.6007 - val_loss: 0.6504 - val_accuracy: 0.6354\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6508 - val_accuracy: 0.6354\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.5972 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4684 - accuracy: 0.6024 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4685 - accuracy: 0.5972 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.5990 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4684 - accuracy: 0.5990 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.6059 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.5990 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.6007 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.5972 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.6024 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.6007 - val_loss: 0.6498 - val_accuracy: 0.6354\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.6007 - val_loss: 0.6498 - val_accuracy: 0.6354\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.5972 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6302\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.5990 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.5972 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4684 - accuracy: 0.5972 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4685 - accuracy: 0.5990 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.5972 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.5972 - val_loss: 0.6499 - val_accuracy: 0.6250\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.6024 - val_loss: 0.6508 - val_accuracy: 0.6354\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.5990 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4682 - accuracy: 0.5955 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4684 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4685 - accuracy: 0.6024 - val_loss: 0.6483 - val_accuracy: 0.6250\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.5972 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.5990 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4682 - accuracy: 0.6007 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.5972 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.5955 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.6024 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4684 - accuracy: 0.5990 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.6007 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.6007 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.5990 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.5972 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4679 - accuracy: 0.5990 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.6094 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4681 - accuracy: 0.5972 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.6007 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6489 - val_accuracy: 0.6354\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4681 - accuracy: 0.5990 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6354\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.6024 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.6059 - val_loss: 0.6504 - val_accuracy: 0.6354\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.5990 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.5938 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 0.6007 - val_loss: 0.6505 - val_accuracy: 0.6354\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4681 - accuracy: 0.6007 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.6007 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.5972 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4681 - accuracy: 0.6024 - val_loss: 0.6498 - val_accuracy: 0.6354\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.6007 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.6042 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.6024 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4681 - accuracy: 0.5990 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.5990 - val_loss: 0.6498 - val_accuracy: 0.6354\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.6007 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.6042 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.6007 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.6007 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.6059 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4678 - accuracy: 0.6059 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.5955 - val_loss: 0.6494 - val_accuracy: 0.6354\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.5990 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.6024 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4680 - accuracy: 0.5990 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.6042 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.6007 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.5990 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.6059 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.6007 - val_loss: 0.6497 - val_accuracy: 0.6354\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.6059 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.5972 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.6007 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.6042 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.6007 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.6007 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.6042 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.6007 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.6042 - val_loss: 0.6517 - val_accuracy: 0.6406\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.6007 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4675 - accuracy: 0.6059 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4677 - accuracy: 0.6024 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.5972 - val_loss: 0.6500 - val_accuracy: 0.6458\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4677 - accuracy: 0.6007 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4675 - accuracy: 0.6024 - val_loss: 0.6499 - val_accuracy: 0.6458\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4676 - accuracy: 0.6042 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4675 - accuracy: 0.6007 - val_loss: 0.6496 - val_accuracy: 0.6458\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4675 - accuracy: 0.5990 - val_loss: 0.6501 - val_accuracy: 0.6458\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4676 - accuracy: 0.6076 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4676 - accuracy: 0.6007 - val_loss: 0.6500 - val_accuracy: 0.6458\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4675 - accuracy: 0.6007 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4674 - accuracy: 0.5972 - val_loss: 0.6502 - val_accuracy: 0.6458\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4676 - accuracy: 0.6042 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4675 - accuracy: 0.6059 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.6007 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4678 - accuracy: 0.6024 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.6024 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.6042 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.6007 - val_loss: 0.6496 - val_accuracy: 0.6458\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4675 - accuracy: 0.5990 - val_loss: 0.6491 - val_accuracy: 0.6458\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4676 - accuracy: 0.6042 - val_loss: 0.6494 - val_accuracy: 0.6458\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4673 - accuracy: 0.6076 - val_loss: 0.6499 - val_accuracy: 0.6458\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.5990 - val_loss: 0.6495 - val_accuracy: 0.6458\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6458\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4674 - accuracy: 0.6076 - val_loss: 0.6493 - val_accuracy: 0.6458\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.6024 - val_loss: 0.6491 - val_accuracy: 0.6458\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.6059 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.6076 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.6059 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4673 - accuracy: 0.6059 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.6024 - val_loss: 0.6501 - val_accuracy: 0.6458\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.6042 - val_loss: 0.6505 - val_accuracy: 0.6458\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.6076 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4673 - accuracy: 0.6059 - val_loss: 0.6498 - val_accuracy: 0.6458\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.6007 - val_loss: 0.6501 - val_accuracy: 0.6458\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.6024 - val_loss: 0.6511 - val_accuracy: 0.6458\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4674 - accuracy: 0.6042 - val_loss: 0.6505 - val_accuracy: 0.6458\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4672 - accuracy: 0.6059 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4672 - accuracy: 0.6111 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4672 - accuracy: 0.6059 - val_loss: 0.6509 - val_accuracy: 0.6458\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4673 - accuracy: 0.6024 - val_loss: 0.6515 - val_accuracy: 0.6458\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4675 - accuracy: 0.6094 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4673 - accuracy: 0.5990 - val_loss: 0.6496 - val_accuracy: 0.6458\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4672 - accuracy: 0.6059 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4674 - accuracy: 0.6007 - val_loss: 0.6505 - val_accuracy: 0.6458\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.6007 - val_loss: 0.6509 - val_accuracy: 0.6458\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4673 - accuracy: 0.6042 - val_loss: 0.6511 - val_accuracy: 0.6458\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.6042 - val_loss: 0.6500 - val_accuracy: 0.6510\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.6007 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4673 - accuracy: 0.6007 - val_loss: 0.6504 - val_accuracy: 0.6458\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4672 - accuracy: 0.6042 - val_loss: 0.6504 - val_accuracy: 0.6458\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.6076 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4670 - accuracy: 0.6042 - val_loss: 0.6518 - val_accuracy: 0.6406\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.6042 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.6059 - val_loss: 0.6505 - val_accuracy: 0.6510\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.6042 - val_loss: 0.6507 - val_accuracy: 0.6510\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.6024 - val_loss: 0.6497 - val_accuracy: 0.6510\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4671 - accuracy: 0.6111 - val_loss: 0.6501 - val_accuracy: 0.6458\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4671 - accuracy: 0.6094 - val_loss: 0.6504 - val_accuracy: 0.6406\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4671 - accuracy: 0.6059 - val_loss: 0.6499 - val_accuracy: 0.6354\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.6094 - val_loss: 0.6497 - val_accuracy: 0.6510\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.6042 - val_loss: 0.6497 - val_accuracy: 0.6510\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.6059 - val_loss: 0.6502 - val_accuracy: 0.6510\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6509 - val_accuracy: 0.6510\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4673 - accuracy: 0.6059 - val_loss: 0.6513 - val_accuracy: 0.6510\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.6094 - val_loss: 0.6524 - val_accuracy: 0.6510\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.6042 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4668 - accuracy: 0.6007 - val_loss: 0.6501 - val_accuracy: 0.6354\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4671 - accuracy: 0.6059 - val_loss: 0.6510 - val_accuracy: 0.6510\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4671 - accuracy: 0.6076 - val_loss: 0.6506 - val_accuracy: 0.6406\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4671 - accuracy: 0.6076 - val_loss: 0.6505 - val_accuracy: 0.6458\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4672 - accuracy: 0.6059 - val_loss: 0.6502 - val_accuracy: 0.6458\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4669 - accuracy: 0.6059 - val_loss: 0.6508 - val_accuracy: 0.6458\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4668 - accuracy: 0.6042 - val_loss: 0.6511 - val_accuracy: 0.6458\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4669 - accuracy: 0.6059 - val_loss: 0.6507 - val_accuracy: 0.6510\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.6059 - val_loss: 0.6513 - val_accuracy: 0.6510\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4669 - accuracy: 0.6024 - val_loss: 0.6506 - val_accuracy: 0.6510\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6504 - val_accuracy: 0.6406\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4669 - accuracy: 0.6024 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4672 - accuracy: 0.6024 - val_loss: 0.6507 - val_accuracy: 0.6510\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.4672 - accuracy: 0.6076 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.6024 - val_loss: 0.6495 - val_accuracy: 0.6510\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4669 - accuracy: 0.6042 - val_loss: 0.6501 - val_accuracy: 0.6510\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4669 - accuracy: 0.6042 - val_loss: 0.6501 - val_accuracy: 0.6510\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4670 - accuracy: 0.6059 - val_loss: 0.6510 - val_accuracy: 0.6406\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.6059 - val_loss: 0.6519 - val_accuracy: 0.6406\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6527 - val_accuracy: 0.6406\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6511 - val_accuracy: 0.6510\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6094 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6094 - val_loss: 0.6503 - val_accuracy: 0.6510\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6042 - val_loss: 0.6497 - val_accuracy: 0.6458\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6076 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6094 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6059 - val_loss: 0.6501 - val_accuracy: 0.6458\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6111 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6094 - val_loss: 0.6502 - val_accuracy: 0.6510\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6059 - val_loss: 0.6505 - val_accuracy: 0.6458\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6510 - val_accuracy: 0.6406\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.6042 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6094 - val_loss: 0.6508 - val_accuracy: 0.6458\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6042 - val_loss: 0.6512 - val_accuracy: 0.6406\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6076 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6042 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6094 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.6042 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6094 - val_loss: 0.6509 - val_accuracy: 0.6458\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.6076 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.6094 - val_loss: 0.6504 - val_accuracy: 0.6458\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6111 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6024 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6094 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.6076 - val_loss: 0.6521 - val_accuracy: 0.6406\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6146 - val_loss: 0.6498 - val_accuracy: 0.6406\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.6076 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.6111 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6076 - val_loss: 0.6516 - val_accuracy: 0.6458\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6059 - val_loss: 0.6521 - val_accuracy: 0.6458\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6076 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.6128 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6059 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.6094 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6111 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6094 - val_loss: 0.6510 - val_accuracy: 0.6458\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6076 - val_loss: 0.6513 - val_accuracy: 0.6458\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6094 - val_loss: 0.6503 - val_accuracy: 0.6406\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6111 - val_loss: 0.6506 - val_accuracy: 0.6406\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.6076 - val_loss: 0.6504 - val_accuracy: 0.6406\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.6128 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6076 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.6042 - val_loss: 0.6506 - val_accuracy: 0.6406\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6076 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.6059 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6111 - val_loss: 0.6515 - val_accuracy: 0.6406\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6128 - val_loss: 0.6525 - val_accuracy: 0.6458\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6111 - val_loss: 0.6512 - val_accuracy: 0.6406\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.6059 - val_loss: 0.6506 - val_accuracy: 0.6406\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6163 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.6076 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.6128 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.6042 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.6111 - val_loss: 0.6527 - val_accuracy: 0.6406\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6076 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.6146 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.6163 - val_loss: 0.6577 - val_accuracy: 0.6458\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6111 - val_loss: 0.6551 - val_accuracy: 0.6406\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.6076 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.6111 - val_loss: 0.6517 - val_accuracy: 0.6406\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6094 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6111 - val_loss: 0.6522 - val_accuracy: 0.6406\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.6111 - val_loss: 0.6519 - val_accuracy: 0.6406\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6128 - val_loss: 0.6509 - val_accuracy: 0.6406\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.6163 - val_loss: 0.6513 - val_accuracy: 0.6354\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6111 - val_loss: 0.6509 - val_accuracy: 0.6354\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.6128 - val_loss: 0.6509 - val_accuracy: 0.6354\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.6111 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6146 - val_loss: 0.6512 - val_accuracy: 0.6406\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.6128 - val_loss: 0.6520 - val_accuracy: 0.6406\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6198 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6076 - val_loss: 0.6503 - val_accuracy: 0.6354\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.6111 - val_loss: 0.6508 - val_accuracy: 0.6354\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6076 - val_loss: 0.6516 - val_accuracy: 0.6354\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.6094 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6146 - val_loss: 0.6529 - val_accuracy: 0.6406\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6076 - val_loss: 0.6523 - val_accuracy: 0.6354\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.6181 - val_loss: 0.6513 - val_accuracy: 0.6354\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6163 - val_loss: 0.6516 - val_accuracy: 0.6354\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6146 - val_loss: 0.6523 - val_accuracy: 0.6354\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.6128 - val_loss: 0.6523 - val_accuracy: 0.6354\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6163 - val_loss: 0.6524 - val_accuracy: 0.6354\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6146 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6163 - val_loss: 0.6520 - val_accuracy: 0.6354\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.6128 - val_loss: 0.6504 - val_accuracy: 0.6354\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6163 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6163 - val_loss: 0.6512 - val_accuracy: 0.6406\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.6111 - val_loss: 0.6520 - val_accuracy: 0.6406\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.6111 - val_loss: 0.6523 - val_accuracy: 0.6406\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.6146 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.6128 - val_loss: 0.6520 - val_accuracy: 0.6354\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6146 - val_loss: 0.6534 - val_accuracy: 0.6354\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.6181 - val_loss: 0.6520 - val_accuracy: 0.6354\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.6163 - val_loss: 0.6527 - val_accuracy: 0.6354\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6128 - val_loss: 0.6526 - val_accuracy: 0.6406\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6128 - val_loss: 0.6522 - val_accuracy: 0.6406\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.6163 - val_loss: 0.6537 - val_accuracy: 0.6406\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.6163 - val_loss: 0.6554 - val_accuracy: 0.6406\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.6111 - val_loss: 0.6519 - val_accuracy: 0.6354\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6146 - val_loss: 0.6534 - val_accuracy: 0.6406\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6354\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.6146 - val_loss: 0.6515 - val_accuracy: 0.6354\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.6128 - val_loss: 0.6516 - val_accuracy: 0.6354\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.6198 - val_loss: 0.6518 - val_accuracy: 0.6354\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.6128 - val_loss: 0.6512 - val_accuracy: 0.6354\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.6128 - val_loss: 0.6516 - val_accuracy: 0.6354\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.6163 - val_loss: 0.6517 - val_accuracy: 0.6354\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.6128 - val_loss: 0.6524 - val_accuracy: 0.6406\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.6146 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.6163 - val_loss: 0.6522 - val_accuracy: 0.6406\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.6181 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.6128 - val_loss: 0.6522 - val_accuracy: 0.6354\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.6128 - val_loss: 0.6528 - val_accuracy: 0.6354\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.6163 - val_loss: 0.6518 - val_accuracy: 0.6354\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6128 - val_loss: 0.6533 - val_accuracy: 0.6354\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.6181 - val_loss: 0.6520 - val_accuracy: 0.6406\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.6128 - val_loss: 0.6529 - val_accuracy: 0.6406\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.6215 - val_loss: 0.6525 - val_accuracy: 0.6354\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.6146 - val_loss: 0.6511 - val_accuracy: 0.6354\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4658 - accuracy: 0.6163 - val_loss: 0.6530 - val_accuracy: 0.6354\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.6198 - val_loss: 0.6519 - val_accuracy: 0.6354\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.6146 - val_loss: 0.6537 - val_accuracy: 0.6354\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.6146 - val_loss: 0.6524 - val_accuracy: 0.6354\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.6215 - val_loss: 0.6516 - val_accuracy: 0.6354\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4656 - accuracy: 0.6198 - val_loss: 0.6512 - val_accuracy: 0.6354\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.6198 - val_loss: 0.6523 - val_accuracy: 0.6354\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4656 - accuracy: 0.6163 - val_loss: 0.6510 - val_accuracy: 0.6354\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.6198 - val_loss: 0.6519 - val_accuracy: 0.6406\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6146 - val_loss: 0.6507 - val_accuracy: 0.6354\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.6163 - val_loss: 0.6513 - val_accuracy: 0.6354\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6198 - val_loss: 0.6519 - val_accuracy: 0.6354\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6516 - val_accuracy: 0.6510\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6146 - val_loss: 0.6537 - val_accuracy: 0.6354\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.6163 - val_loss: 0.6532 - val_accuracy: 0.6354\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6181 - val_loss: 0.6533 - val_accuracy: 0.6458\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6181 - val_loss: 0.6524 - val_accuracy: 0.6354\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6163 - val_loss: 0.6509 - val_accuracy: 0.6458\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.6163 - val_loss: 0.6520 - val_accuracy: 0.6458\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6128 - val_loss: 0.6531 - val_accuracy: 0.6354\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6233 - val_loss: 0.6547 - val_accuracy: 0.6354\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.6146 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.6163 - val_loss: 0.6525 - val_accuracy: 0.6458\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6163 - val_loss: 0.6511 - val_accuracy: 0.6510\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6146 - val_loss: 0.6515 - val_accuracy: 0.6510\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.6198 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6181 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6198 - val_loss: 0.6531 - val_accuracy: 0.6354\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.6233 - val_loss: 0.6525 - val_accuracy: 0.6354\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6198 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6163 - val_loss: 0.6534 - val_accuracy: 0.6354\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.6198 - val_loss: 0.6561 - val_accuracy: 0.6354\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.6215 - val_loss: 0.6543 - val_accuracy: 0.6354\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6519 - val_accuracy: 0.6458\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6508 - val_accuracy: 0.6458\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.6163 - val_loss: 0.6512 - val_accuracy: 0.6458\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6181 - val_loss: 0.6542 - val_accuracy: 0.6354\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6198 - val_loss: 0.6589 - val_accuracy: 0.6406\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.6198 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.6146 - val_loss: 0.6530 - val_accuracy: 0.6458\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.6181 - val_loss: 0.6524 - val_accuracy: 0.6458\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.6163 - val_loss: 0.6540 - val_accuracy: 0.6458\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6215 - val_loss: 0.6529 - val_accuracy: 0.6458\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6128 - val_loss: 0.6515 - val_accuracy: 0.6458\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6181 - val_loss: 0.6529 - val_accuracy: 0.6458\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6458\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6198 - val_loss: 0.6520 - val_accuracy: 0.6458\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6511 - val_accuracy: 0.6458\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6181 - val_loss: 0.6538 - val_accuracy: 0.6458\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6215 - val_loss: 0.6507 - val_accuracy: 0.6458\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6163 - val_loss: 0.6538 - val_accuracy: 0.6458\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6233 - val_loss: 0.6540 - val_accuracy: 0.6458\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.6181 - val_loss: 0.6539 - val_accuracy: 0.6458\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.6163 - val_loss: 0.6526 - val_accuracy: 0.6458\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6181 - val_loss: 0.6555 - val_accuracy: 0.6458\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.6181 - val_loss: 0.6582 - val_accuracy: 0.6458\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.6198 - val_loss: 0.6572 - val_accuracy: 0.6458\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.6198 - val_loss: 0.6535 - val_accuracy: 0.6458\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6163 - val_loss: 0.6565 - val_accuracy: 0.6458\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6181 - val_loss: 0.6546 - val_accuracy: 0.6458\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.6233 - val_loss: 0.6529 - val_accuracy: 0.6458\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6163 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6458\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.6181 - val_loss: 0.6534 - val_accuracy: 0.6458\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6146 - val_loss: 0.6535 - val_accuracy: 0.6458\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6181 - val_loss: 0.6541 - val_accuracy: 0.6458\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6146 - val_loss: 0.6542 - val_accuracy: 0.6458\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.6215 - val_loss: 0.6562 - val_accuracy: 0.6458\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.6198 - val_loss: 0.6550 - val_accuracy: 0.6458\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6163 - val_loss: 0.6525 - val_accuracy: 0.6458\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6181 - val_loss: 0.6533 - val_accuracy: 0.6458\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6233 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6198 - val_loss: 0.6553 - val_accuracy: 0.6458\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6215 - val_loss: 0.6572 - val_accuracy: 0.6458\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6198 - val_loss: 0.6556 - val_accuracy: 0.6458\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6250 - val_loss: 0.6537 - val_accuracy: 0.6458\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.6198 - val_loss: 0.6539 - val_accuracy: 0.6458\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.6163 - val_loss: 0.6539 - val_accuracy: 0.6458\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.6181 - val_loss: 0.6541 - val_accuracy: 0.6458\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.6215 - val_loss: 0.6557 - val_accuracy: 0.6458\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6215 - val_loss: 0.6558 - val_accuracy: 0.6458\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6198 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.6215 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6198 - val_loss: 0.6535 - val_accuracy: 0.6458\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6215 - val_loss: 0.6543 - val_accuracy: 0.6458\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6128 - val_loss: 0.6548 - val_accuracy: 0.6458\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.6181 - val_loss: 0.6585 - val_accuracy: 0.6458\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6233 - val_loss: 0.6550 - val_accuracy: 0.6458\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6215 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.6198 - val_loss: 0.6546 - val_accuracy: 0.6458\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.6215 - val_loss: 0.6542 - val_accuracy: 0.6458\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.6233 - val_loss: 0.6561 - val_accuracy: 0.6458\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.6181 - val_loss: 0.6575 - val_accuracy: 0.6458\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6181 - val_loss: 0.6549 - val_accuracy: 0.6458\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.6233 - val_loss: 0.6536 - val_accuracy: 0.6458\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.6181 - val_loss: 0.6543 - val_accuracy: 0.6458\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6250 - val_loss: 0.6545 - val_accuracy: 0.6458\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6524 - val_accuracy: 0.6458\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.6181 - val_loss: 0.6554 - val_accuracy: 0.6458\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6198 - val_loss: 0.6553 - val_accuracy: 0.6458\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.6163 - val_loss: 0.6607 - val_accuracy: 0.6458\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.6163 - val_loss: 0.6547 - val_accuracy: 0.6458\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6780 - val_accuracy: 0.6458\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6563 - val_accuracy: 0.6458\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6557 - val_accuracy: 0.6458\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6267 - val_loss: 0.6533 - val_accuracy: 0.6458\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6582 - val_accuracy: 0.6458\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6549 - val_accuracy: 0.6458\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.6215 - val_loss: 0.6530 - val_accuracy: 0.6458\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6555 - val_accuracy: 0.6458\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.6198 - val_loss: 0.6548 - val_accuracy: 0.6458\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6601 - val_accuracy: 0.6458\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.6233 - val_loss: 0.6587 - val_accuracy: 0.6458\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.6233 - val_loss: 0.6599 - val_accuracy: 0.6458\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6557 - val_accuracy: 0.6458\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6553 - val_accuracy: 0.6458\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.6146 - val_loss: 0.6586 - val_accuracy: 0.6458\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.6198 - val_loss: 0.6585 - val_accuracy: 0.6458\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.6233 - val_loss: 0.6781 - val_accuracy: 0.6458\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.6181 - val_loss: 0.6784 - val_accuracy: 0.6458\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.6181 - val_loss: 0.6782 - val_accuracy: 0.6458\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.6267 - val_loss: 0.6565 - val_accuracy: 0.6458\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.6181 - val_loss: 0.6564 - val_accuracy: 0.6458\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.6215 - val_loss: 0.6590 - val_accuracy: 0.6458\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.6163 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.6198 - val_loss: 0.6562 - val_accuracy: 0.6458\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.6233 - val_loss: 0.6584 - val_accuracy: 0.6458\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.6181 - val_loss: 0.6568 - val_accuracy: 0.6458\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.6215 - val_loss: 0.6777 - val_accuracy: 0.6458\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.6181 - val_loss: 0.6781 - val_accuracy: 0.6458\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.6215 - val_loss: 0.6778 - val_accuracy: 0.6458\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.6198 - val_loss: 0.6779 - val_accuracy: 0.6458\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.6250 - val_loss: 0.6776 - val_accuracy: 0.6458\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.6215 - val_loss: 0.6568 - val_accuracy: 0.6458\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6777 - val_accuracy: 0.6458\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.6233 - val_loss: 0.6785 - val_accuracy: 0.6458\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.6163 - val_loss: 0.6782 - val_accuracy: 0.6458\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.6233 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.6198 - val_loss: 0.6777 - val_accuracy: 0.6458\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4645 - accuracy: 0.6198 - val_loss: 0.6600 - val_accuracy: 0.6458\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4645 - accuracy: 0.6215 - val_loss: 0.6591 - val_accuracy: 0.6406\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.6233 - val_loss: 0.6778 - val_accuracy: 0.6458\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.6215 - val_loss: 0.6784 - val_accuracy: 0.6406\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6215 - val_loss: 0.6614 - val_accuracy: 0.6406\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.6215 - val_loss: 0.6564 - val_accuracy: 0.6406\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6563 - val_accuracy: 0.6406\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.6198 - val_loss: 0.6777 - val_accuracy: 0.6458\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.6233 - val_loss: 0.6775 - val_accuracy: 0.6458\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6181 - val_loss: 0.6779 - val_accuracy: 0.6406\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6215 - val_loss: 0.6778 - val_accuracy: 0.6458\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6785 - val_accuracy: 0.6406\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6215 - val_loss: 0.6608 - val_accuracy: 0.6406\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.6198 - val_loss: 0.6783 - val_accuracy: 0.6406\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6787 - val_accuracy: 0.6406\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6215 - val_loss: 0.6789 - val_accuracy: 0.6406\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6215 - val_loss: 0.6780 - val_accuracy: 0.6406\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.6215 - val_loss: 0.6779 - val_accuracy: 0.6406\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6233 - val_loss: 0.6778 - val_accuracy: 0.6406\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6181 - val_loss: 0.6786 - val_accuracy: 0.6406\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.6233 - val_loss: 0.6781 - val_accuracy: 0.6406\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6198 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6181 - val_loss: 0.6784 - val_accuracy: 0.6406\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.6198 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6181 - val_loss: 0.6780 - val_accuracy: 0.6406\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.6181 - val_loss: 0.6785 - val_accuracy: 0.6406\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.6233 - val_loss: 0.6778 - val_accuracy: 0.6406\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6215 - val_loss: 0.6779 - val_accuracy: 0.6406\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6163 - val_loss: 0.6791 - val_accuracy: 0.6406\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.6181 - val_loss: 0.6785 - val_accuracy: 0.6406\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6198 - val_loss: 0.6783 - val_accuracy: 0.6406\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6163 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6181 - val_loss: 0.6781 - val_accuracy: 0.6406\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6250 - val_loss: 0.6548 - val_accuracy: 0.6406\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.6181 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6163 - val_loss: 0.6778 - val_accuracy: 0.6406\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6198 - val_loss: 0.6565 - val_accuracy: 0.6406\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.6198 - val_loss: 0.6585 - val_accuracy: 0.6406\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6215 - val_loss: 0.6776 - val_accuracy: 0.6406\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6198 - val_loss: 0.6776 - val_accuracy: 0.6354\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6181 - val_loss: 0.6777 - val_accuracy: 0.6354\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6146 - val_loss: 0.6565 - val_accuracy: 0.6354\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6215 - val_loss: 0.6775 - val_accuracy: 0.6354\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.6181 - val_loss: 0.6777 - val_accuracy: 0.6354\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.6233 - val_loss: 0.6778 - val_accuracy: 0.6406\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6233 - val_loss: 0.6773 - val_accuracy: 0.6510\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6198 - val_loss: 0.6773 - val_accuracy: 0.6510\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6198 - val_loss: 0.6776 - val_accuracy: 0.6510\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.6181 - val_loss: 0.6789 - val_accuracy: 0.6510\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6215 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6215 - val_loss: 0.6777 - val_accuracy: 0.6354\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6793 - val_accuracy: 0.6354\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6198 - val_loss: 0.6803 - val_accuracy: 0.6406\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6198 - val_loss: 0.6788 - val_accuracy: 0.6354\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6250 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6250 - val_loss: 0.6779 - val_accuracy: 0.6354\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6215 - val_loss: 0.6778 - val_accuracy: 0.6458\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6198 - val_loss: 0.6780 - val_accuracy: 0.6354\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6215 - val_loss: 0.6777 - val_accuracy: 0.6406\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.6198 - val_loss: 0.6779 - val_accuracy: 0.6354\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.6215 - val_loss: 0.6777 - val_accuracy: 0.6354\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6128 - val_loss: 0.6784 - val_accuracy: 0.6354\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6250 - val_loss: 0.6779 - val_accuracy: 0.6458\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6181 - val_loss: 0.6781 - val_accuracy: 0.6354\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6198 - val_loss: 0.6777 - val_accuracy: 0.6354\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6198 - val_loss: 0.6780 - val_accuracy: 0.6406\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6783 - val_accuracy: 0.6354\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6146 - val_loss: 0.6783 - val_accuracy: 0.6406\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6198 - val_loss: 0.6782 - val_accuracy: 0.6354\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.6163 - val_loss: 0.6784 - val_accuracy: 0.6458\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6790 - val_accuracy: 0.6354\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6198 - val_loss: 0.6788 - val_accuracy: 0.6354\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6198 - val_loss: 0.6795 - val_accuracy: 0.6354\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6198 - val_loss: 0.6789 - val_accuracy: 0.6354\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.6198 - val_loss: 0.6788 - val_accuracy: 0.6406\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.6163 - val_loss: 0.6784 - val_accuracy: 0.6354\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6780 - val_accuracy: 0.6406\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6233 - val_loss: 0.6779 - val_accuracy: 0.6458\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6780 - val_accuracy: 0.6458\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6146 - val_loss: 0.6778 - val_accuracy: 0.6458\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6775 - val_accuracy: 0.6458\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6215 - val_loss: 0.6779 - val_accuracy: 0.6458\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6163 - val_loss: 0.6781 - val_accuracy: 0.6458\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6788 - val_accuracy: 0.6354\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.6181 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.6181 - val_loss: 0.6791 - val_accuracy: 0.6354\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6233 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6783 - val_accuracy: 0.6354\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6792 - val_accuracy: 0.6354\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6198 - val_loss: 0.6791 - val_accuracy: 0.6354\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6267 - val_loss: 0.6779 - val_accuracy: 0.6354\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.6215 - val_loss: 0.6776 - val_accuracy: 0.6354\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6163 - val_loss: 0.6783 - val_accuracy: 0.6354\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.6198 - val_loss: 0.6785 - val_accuracy: 0.6354\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6181 - val_loss: 0.6793 - val_accuracy: 0.6354\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6181 - val_loss: 0.6789 - val_accuracy: 0.6354\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.6163 - val_loss: 0.6781 - val_accuracy: 0.6354\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.6250 - val_loss: 0.6781 - val_accuracy: 0.6458\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6181 - val_loss: 0.6779 - val_accuracy: 0.6354\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.6198 - val_loss: 0.6777 - val_accuracy: 0.6406\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.6181 - val_loss: 0.6785 - val_accuracy: 0.6354\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.6128 - val_loss: 0.6804 - val_accuracy: 0.6354\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.6215 - val_loss: 0.6788 - val_accuracy: 0.6458\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.6181 - val_loss: 0.6787 - val_accuracy: 0.6458\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.6215 - val_loss: 0.6781 - val_accuracy: 0.6458\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.6181 - val_loss: 0.6791 - val_accuracy: 0.6458\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4634 - accuracy: 0.6181 - val_loss: 0.6780 - val_accuracy: 0.6406\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.6198 - val_loss: 0.6779 - val_accuracy: 0.6354\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6780 - val_accuracy: 0.6354\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.6198 - val_loss: 0.6785 - val_accuracy: 0.6406\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.6198 - val_loss: 0.6787 - val_accuracy: 0.6354\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.6163 - val_loss: 0.6795 - val_accuracy: 0.6354\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.6233 - val_loss: 0.6794 - val_accuracy: 0.6354\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.6146 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6789 - val_accuracy: 0.6354\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4636 - accuracy: 0.6198 - val_loss: 0.6786 - val_accuracy: 0.6354\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.6163 - val_loss: 0.6790 - val_accuracy: 0.6354\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.6146 - val_loss: 0.6792 - val_accuracy: 0.6458\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.6163 - val_loss: 0.6801 - val_accuracy: 0.6458\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4634 - accuracy: 0.6198 - val_loss: 0.6793 - val_accuracy: 0.6354\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.6181 - val_loss: 0.6798 - val_accuracy: 0.6354\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.6181 - val_loss: 0.6793 - val_accuracy: 0.6354\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.6215 - val_loss: 0.6791 - val_accuracy: 0.6406\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4635 - accuracy: 0.6215 - val_loss: 0.6787 - val_accuracy: 0.6406\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4637 - accuracy: 0.6215 - val_loss: 0.6795 - val_accuracy: 0.6354\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4635 - accuracy: 0.6233 - val_loss: 0.6796 - val_accuracy: 0.6354\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.6215 - val_loss: 0.6785 - val_accuracy: 0.6458\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.6181 - val_loss: 0.6795 - val_accuracy: 0.6458\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4634 - accuracy: 0.6198 - val_loss: 0.6787 - val_accuracy: 0.6458\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.6198 - val_loss: 0.6811 - val_accuracy: 0.6458\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6793 - val_accuracy: 0.6354\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.6181 - val_loss: 0.6795 - val_accuracy: 0.6458\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.6198 - val_loss: 0.6792 - val_accuracy: 0.6406\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.6146 - val_loss: 0.6799 - val_accuracy: 0.6458\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6198 - val_loss: 0.6803 - val_accuracy: 0.6406\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.6181 - val_loss: 0.6813 - val_accuracy: 0.6458\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.6163 - val_loss: 0.6797 - val_accuracy: 0.6458\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.6181 - val_loss: 0.6804 - val_accuracy: 0.6458\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.6163 - val_loss: 0.7034 - val_accuracy: 0.6510\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6198 - val_loss: 0.6835 - val_accuracy: 0.6354\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.6181 - val_loss: 0.6808 - val_accuracy: 0.6354\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.6181 - val_loss: 0.6804 - val_accuracy: 0.6354\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6215 - val_loss: 0.6790 - val_accuracy: 0.6458\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.6163 - val_loss: 0.6798 - val_accuracy: 0.6458\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6163 - val_loss: 0.6797 - val_accuracy: 0.6458\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.6128 - val_loss: 0.6789 - val_accuracy: 0.6354\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.6198 - val_loss: 0.6811 - val_accuracy: 0.6354\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.6163 - val_loss: 0.6810 - val_accuracy: 0.6354\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.6198 - val_loss: 0.6817 - val_accuracy: 0.6458\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.6181 - val_loss: 0.6800 - val_accuracy: 0.6354\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.6181 - val_loss: 0.6805 - val_accuracy: 0.6458\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.6198 - val_loss: 0.6794 - val_accuracy: 0.6458\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.6181 - val_loss: 0.6786 - val_accuracy: 0.6406\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.6181 - val_loss: 0.6791 - val_accuracy: 0.6458\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6181 - val_loss: 0.6816 - val_accuracy: 0.6458\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4631 - accuracy: 0.6181 - val_loss: 0.6902 - val_accuracy: 0.6458\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.6198 - val_loss: 0.6801 - val_accuracy: 0.6458\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.6163 - val_loss: 0.6800 - val_accuracy: 0.6406\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.6198 - val_loss: 0.6795 - val_accuracy: 0.6406\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.6146 - val_loss: 0.6787 - val_accuracy: 0.6354\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.6198 - val_loss: 0.6803 - val_accuracy: 0.6406\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.6181 - val_loss: 0.6806 - val_accuracy: 0.6458\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.6198 - val_loss: 0.6790 - val_accuracy: 0.6458\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.6163 - val_loss: 0.6790 - val_accuracy: 0.6406\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.6215 - val_loss: 0.6802 - val_accuracy: 0.6458\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.6163 - val_loss: 0.6898 - val_accuracy: 0.6458\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.6181 - val_loss: 0.6822 - val_accuracy: 0.6406\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.6215 - val_loss: 0.7033 - val_accuracy: 0.6458\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.6181 - val_loss: 0.6820 - val_accuracy: 0.6406\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.6198 - val_loss: 0.6811 - val_accuracy: 0.6354\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.6163 - val_loss: 0.6794 - val_accuracy: 0.6406\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.6215 - val_loss: 0.6813 - val_accuracy: 0.6458\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.6163 - val_loss: 0.6801 - val_accuracy: 0.6406\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.6163 - val_loss: 0.6807 - val_accuracy: 0.6458\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.6215 - val_loss: 0.6814 - val_accuracy: 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "04xeu5CDdaN-",
        "outputId": "6fd57215-b242-433b-a924-13ecd8e12e2c"
      },
      "id": "04xeu5CDdaN-",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x782d215b2500>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the roc curve for the predictions\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,Rf.predict(X_test))))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,Rf.predict_proba(X_test)[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "PQN25rj1uyvz",
        "outputId": "9ae48223-a2f5-4872-80ce-2d540e9c6ead"
      },
      "id": "PQN25rj1uyvz",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.833\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use different learning rates, numbers of epochs, and network structures.\n",
        "model_2 = Sequential([\n",
        "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "U6ugLzmGv3K_"
      },
      "id": "U6ugLzmGv3K_",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuhsM7Vl0yBq",
        "outputId": "036b10a5-e740-4037-eb7c-7e16e73fceb8"
      },
      "id": "HuhsM7Vl0yBq",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 105 (420.00 Byte)\n",
            "Trainable params: 105 (420.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(SGD(learning_rate=0.001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c4Nj0DYv4ub",
        "outputId": "58ed7949-c473-4457-dff3-56ce19a083f6"
      },
      "id": "_c4Nj0DYv4ub",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 2s 26ms/step - loss: 0.9197 - accuracy: 0.4028 - val_loss: 0.9939 - val_accuracy: 0.3854\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9157 - accuracy: 0.4028 - val_loss: 0.9892 - val_accuracy: 0.3854\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9116 - accuracy: 0.4028 - val_loss: 0.9845 - val_accuracy: 0.3854\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.9076 - accuracy: 0.4028 - val_loss: 0.9800 - val_accuracy: 0.3854\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9037 - accuracy: 0.4062 - val_loss: 0.9755 - val_accuracy: 0.3802\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.8998 - accuracy: 0.4097 - val_loss: 0.9711 - val_accuracy: 0.3854\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8961 - accuracy: 0.4115 - val_loss: 0.9667 - val_accuracy: 0.3854\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.8923 - accuracy: 0.4132 - val_loss: 0.9624 - val_accuracy: 0.3854\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.8887 - accuracy: 0.4149 - val_loss: 0.9582 - val_accuracy: 0.3854\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.8850 - accuracy: 0.4167 - val_loss: 0.9540 - val_accuracy: 0.3854\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8815 - accuracy: 0.4167 - val_loss: 0.9499 - val_accuracy: 0.3958\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8780 - accuracy: 0.4201 - val_loss: 0.9459 - val_accuracy: 0.4010\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8745 - accuracy: 0.4219 - val_loss: 0.9419 - val_accuracy: 0.4010\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8711 - accuracy: 0.4219 - val_loss: 0.9379 - val_accuracy: 0.4010\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8678 - accuracy: 0.4236 - val_loss: 0.9341 - val_accuracy: 0.4010\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.4236 - val_loss: 0.9303 - val_accuracy: 0.4010\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8612 - accuracy: 0.4236 - val_loss: 0.9265 - val_accuracy: 0.4062\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8580 - accuracy: 0.4253 - val_loss: 0.9228 - val_accuracy: 0.4115\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8548 - accuracy: 0.4306 - val_loss: 0.9191 - val_accuracy: 0.4115\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8518 - accuracy: 0.4392 - val_loss: 0.9155 - val_accuracy: 0.4167\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8487 - accuracy: 0.4444 - val_loss: 0.9120 - val_accuracy: 0.4167\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8457 - accuracy: 0.4462 - val_loss: 0.9085 - val_accuracy: 0.4271\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8427 - accuracy: 0.4479 - val_loss: 0.9050 - val_accuracy: 0.4323\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8397 - accuracy: 0.4531 - val_loss: 0.9016 - val_accuracy: 0.4271\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.4549 - val_loss: 0.8983 - val_accuracy: 0.4323\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8340 - accuracy: 0.4549 - val_loss: 0.8949 - val_accuracy: 0.4323\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8312 - accuracy: 0.4601 - val_loss: 0.8917 - val_accuracy: 0.4323\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8284 - accuracy: 0.4601 - val_loss: 0.8885 - val_accuracy: 0.4323\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.4618 - val_loss: 0.8853 - val_accuracy: 0.4323\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8230 - accuracy: 0.4618 - val_loss: 0.8822 - val_accuracy: 0.4375\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8204 - accuracy: 0.4635 - val_loss: 0.8792 - val_accuracy: 0.4375\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8178 - accuracy: 0.4670 - val_loss: 0.8761 - val_accuracy: 0.4375\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.4688 - val_loss: 0.8732 - val_accuracy: 0.4375\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8127 - accuracy: 0.4705 - val_loss: 0.8702 - val_accuracy: 0.4375\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8102 - accuracy: 0.4722 - val_loss: 0.8673 - val_accuracy: 0.4375\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8078 - accuracy: 0.4722 - val_loss: 0.8644 - val_accuracy: 0.4375\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8053 - accuracy: 0.4774 - val_loss: 0.8616 - val_accuracy: 0.4375\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8029 - accuracy: 0.4809 - val_loss: 0.8588 - val_accuracy: 0.4375\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8006 - accuracy: 0.4809 - val_loss: 0.8561 - val_accuracy: 0.4427\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.4826 - val_loss: 0.8533 - val_accuracy: 0.4427\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7960 - accuracy: 0.4809 - val_loss: 0.8507 - val_accuracy: 0.4479\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7937 - accuracy: 0.4844 - val_loss: 0.8480 - val_accuracy: 0.4479\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.4844 - val_loss: 0.8454 - val_accuracy: 0.4531\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7893 - accuracy: 0.4896 - val_loss: 0.8428 - val_accuracy: 0.4583\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.4896 - val_loss: 0.8402 - val_accuracy: 0.4688\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7850 - accuracy: 0.4931 - val_loss: 0.8377 - val_accuracy: 0.4688\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.5000 - val_loss: 0.8352 - val_accuracy: 0.4740\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.5000 - val_loss: 0.8328 - val_accuracy: 0.4688\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.5035 - val_loss: 0.8304 - val_accuracy: 0.4688\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7767 - accuracy: 0.5104 - val_loss: 0.8280 - val_accuracy: 0.4740\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.5087 - val_loss: 0.8256 - val_accuracy: 0.4792\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.5104 - val_loss: 0.8233 - val_accuracy: 0.4792\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7707 - accuracy: 0.5122 - val_loss: 0.8210 - val_accuracy: 0.4792\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7688 - accuracy: 0.5139 - val_loss: 0.8187 - val_accuracy: 0.4792\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7668 - accuracy: 0.5156 - val_loss: 0.8165 - val_accuracy: 0.4792\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7650 - accuracy: 0.5191 - val_loss: 0.8143 - val_accuracy: 0.4792\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7631 - accuracy: 0.5191 - val_loss: 0.8121 - val_accuracy: 0.4844\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7612 - accuracy: 0.5191 - val_loss: 0.8099 - val_accuracy: 0.4844\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7594 - accuracy: 0.5191 - val_loss: 0.8077 - val_accuracy: 0.4844\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7576 - accuracy: 0.5208 - val_loss: 0.8056 - val_accuracy: 0.4844\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7558 - accuracy: 0.5208 - val_loss: 0.8035 - val_accuracy: 0.4844\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7541 - accuracy: 0.5226 - val_loss: 0.8015 - val_accuracy: 0.4948\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7523 - accuracy: 0.5243 - val_loss: 0.7994 - val_accuracy: 0.4948\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7506 - accuracy: 0.5278 - val_loss: 0.7974 - val_accuracy: 0.4948\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7490 - accuracy: 0.5295 - val_loss: 0.7954 - val_accuracy: 0.5000\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7473 - accuracy: 0.5365 - val_loss: 0.7934 - val_accuracy: 0.5052\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7456 - accuracy: 0.5399 - val_loss: 0.7915 - val_accuracy: 0.5156\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7440 - accuracy: 0.5399 - val_loss: 0.7896 - val_accuracy: 0.5104\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.5451 - val_loss: 0.7877 - val_accuracy: 0.5104\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7408 - accuracy: 0.5434 - val_loss: 0.7858 - val_accuracy: 0.5104\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7392 - accuracy: 0.5486 - val_loss: 0.7839 - val_accuracy: 0.5208\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.5469 - val_loss: 0.7821 - val_accuracy: 0.5208\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7361 - accuracy: 0.5503 - val_loss: 0.7803 - val_accuracy: 0.5208\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7346 - accuracy: 0.5556 - val_loss: 0.7785 - val_accuracy: 0.5260\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7331 - accuracy: 0.5573 - val_loss: 0.7767 - val_accuracy: 0.5312\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7316 - accuracy: 0.5608 - val_loss: 0.7750 - val_accuracy: 0.5365\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7302 - accuracy: 0.5642 - val_loss: 0.7732 - val_accuracy: 0.5417\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7287 - accuracy: 0.5677 - val_loss: 0.7715 - val_accuracy: 0.5469\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.5712 - val_loss: 0.7698 - val_accuracy: 0.5469\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.5764 - val_loss: 0.7682 - val_accuracy: 0.5521\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.5747 - val_loss: 0.7665 - val_accuracy: 0.5573\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.5799 - val_loss: 0.7649 - val_accuracy: 0.5573\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.5799 - val_loss: 0.7632 - val_accuracy: 0.5625\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7203 - accuracy: 0.5851 - val_loss: 0.7616 - val_accuracy: 0.5625\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.5885 - val_loss: 0.7601 - val_accuracy: 0.5625\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.5868 - val_loss: 0.7585 - val_accuracy: 0.5729\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.5885 - val_loss: 0.7569 - val_accuracy: 0.5729\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.5938 - val_loss: 0.7554 - val_accuracy: 0.5729\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.6007 - val_loss: 0.7539 - val_accuracy: 0.5781\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.6076 - val_loss: 0.7524 - val_accuracy: 0.5781\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.6076 - val_loss: 0.7509 - val_accuracy: 0.5885\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.6128 - val_loss: 0.7494 - val_accuracy: 0.5938\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.6181 - val_loss: 0.7480 - val_accuracy: 0.5938\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.6198 - val_loss: 0.7465 - val_accuracy: 0.5938\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.6250 - val_loss: 0.7451 - val_accuracy: 0.5938\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.6250 - val_loss: 0.7437 - val_accuracy: 0.5990\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.6267 - val_loss: 0.7423 - val_accuracy: 0.6094\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.6302 - val_loss: 0.7409 - val_accuracy: 0.6146\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.6302 - val_loss: 0.7395 - val_accuracy: 0.6146\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.6319 - val_loss: 0.7382 - val_accuracy: 0.6146\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.6354 - val_loss: 0.7368 - val_accuracy: 0.6146\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.6372 - val_loss: 0.7355 - val_accuracy: 0.6146\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.6372 - val_loss: 0.7341 - val_accuracy: 0.6146\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.6372 - val_loss: 0.7328 - val_accuracy: 0.6146\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.6424 - val_loss: 0.7315 - val_accuracy: 0.6146\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6424 - val_loss: 0.7303 - val_accuracy: 0.6302\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.6441 - val_loss: 0.7290 - val_accuracy: 0.6302\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.6458 - val_loss: 0.7277 - val_accuracy: 0.6354\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.6458 - val_loss: 0.7265 - val_accuracy: 0.6406\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.6458 - val_loss: 0.7252 - val_accuracy: 0.6406\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.6458 - val_loss: 0.7240 - val_accuracy: 0.6406\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6441 - val_loss: 0.7228 - val_accuracy: 0.6406\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6510 - val_loss: 0.7216 - val_accuracy: 0.6406\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.6510 - val_loss: 0.7204 - val_accuracy: 0.6406\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6545 - val_loss: 0.7192 - val_accuracy: 0.6354\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.6562 - val_loss: 0.7180 - val_accuracy: 0.6354\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6597 - val_loss: 0.7169 - val_accuracy: 0.6302\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6649 - val_loss: 0.7157 - val_accuracy: 0.6302\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.6684 - val_loss: 0.7146 - val_accuracy: 0.6250\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6684 - val_loss: 0.7135 - val_accuracy: 0.6250\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.6684 - val_loss: 0.7123 - val_accuracy: 0.6250\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6684 - val_loss: 0.7112 - val_accuracy: 0.6250\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.6701 - val_loss: 0.7101 - val_accuracy: 0.6302\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.6701 - val_loss: 0.7090 - val_accuracy: 0.6354\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6719 - val_loss: 0.7079 - val_accuracy: 0.6354\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6701 - val_loss: 0.7069 - val_accuracy: 0.6354\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6736 - val_loss: 0.7058 - val_accuracy: 0.6302\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6753 - val_loss: 0.7047 - val_accuracy: 0.6302\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6771 - val_loss: 0.7037 - val_accuracy: 0.6302\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6771 - val_loss: 0.7026 - val_accuracy: 0.6302\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6788 - val_loss: 0.7016 - val_accuracy: 0.6302\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6771 - val_loss: 0.7006 - val_accuracy: 0.6302\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6788 - val_loss: 0.6995 - val_accuracy: 0.6302\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6788 - val_loss: 0.6985 - val_accuracy: 0.6302\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6788 - val_loss: 0.6975 - val_accuracy: 0.6302\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.6806 - val_loss: 0.6965 - val_accuracy: 0.6302\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6840 - val_loss: 0.6955 - val_accuracy: 0.6302\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6823 - val_loss: 0.6945 - val_accuracy: 0.6354\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6823 - val_loss: 0.6936 - val_accuracy: 0.6354\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6840 - val_loss: 0.6926 - val_accuracy: 0.6354\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6840 - val_loss: 0.6916 - val_accuracy: 0.6458\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6858 - val_loss: 0.6907 - val_accuracy: 0.6510\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6840 - val_loss: 0.6897 - val_accuracy: 0.6458\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6840 - val_loss: 0.6888 - val_accuracy: 0.6458\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6823 - val_loss: 0.6878 - val_accuracy: 0.6458\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6823 - val_loss: 0.6869 - val_accuracy: 0.6458\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6840 - val_loss: 0.6860 - val_accuracy: 0.6458\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6858 - val_loss: 0.6851 - val_accuracy: 0.6458\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6858 - val_loss: 0.6841 - val_accuracy: 0.6458\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6840 - val_loss: 0.6832 - val_accuracy: 0.6458\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6858 - val_loss: 0.6824 - val_accuracy: 0.6458\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6858 - val_loss: 0.6815 - val_accuracy: 0.6458\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6858 - val_loss: 0.6806 - val_accuracy: 0.6458\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6858 - val_loss: 0.6797 - val_accuracy: 0.6458\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6858 - val_loss: 0.6789 - val_accuracy: 0.6458\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6858 - val_loss: 0.6780 - val_accuracy: 0.6458\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6858 - val_loss: 0.6771 - val_accuracy: 0.6458\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6892 - val_loss: 0.6763 - val_accuracy: 0.6458\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6892 - val_loss: 0.6755 - val_accuracy: 0.6458\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6892 - val_loss: 0.6746 - val_accuracy: 0.6458\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6892 - val_loss: 0.6738 - val_accuracy: 0.6458\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6910 - val_loss: 0.6730 - val_accuracy: 0.6458\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6927 - val_loss: 0.6722 - val_accuracy: 0.6458\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6892 - val_loss: 0.6714 - val_accuracy: 0.6458\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6892 - val_loss: 0.6706 - val_accuracy: 0.6458\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6927 - val_loss: 0.6698 - val_accuracy: 0.6458\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6910 - val_loss: 0.6690 - val_accuracy: 0.6458\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6927 - val_loss: 0.6682 - val_accuracy: 0.6510\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6910 - val_loss: 0.6674 - val_accuracy: 0.6510\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6910 - val_loss: 0.6666 - val_accuracy: 0.6510\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6892 - val_loss: 0.6659 - val_accuracy: 0.6510\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6892 - val_loss: 0.6651 - val_accuracy: 0.6510\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6892 - val_loss: 0.6644 - val_accuracy: 0.6510\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6927 - val_loss: 0.6636 - val_accuracy: 0.6510\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6944 - val_loss: 0.6629 - val_accuracy: 0.6510\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.6979 - val_loss: 0.6621 - val_accuracy: 0.6510\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6997 - val_loss: 0.6614 - val_accuracy: 0.6510\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6997 - val_loss: 0.6607 - val_accuracy: 0.6562\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7014 - val_loss: 0.6599 - val_accuracy: 0.6615\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7031 - val_loss: 0.6592 - val_accuracy: 0.6615\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7031 - val_loss: 0.6585 - val_accuracy: 0.6615\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.7014 - val_loss: 0.6578 - val_accuracy: 0.6615\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7014 - val_loss: 0.6571 - val_accuracy: 0.6615\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7014 - val_loss: 0.6564 - val_accuracy: 0.6615\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7031 - val_loss: 0.6557 - val_accuracy: 0.6615\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.7031 - val_loss: 0.6550 - val_accuracy: 0.6615\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.7014 - val_loss: 0.6543 - val_accuracy: 0.6615\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7066 - val_loss: 0.6537 - val_accuracy: 0.6615\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7066 - val_loss: 0.6530 - val_accuracy: 0.6615\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7066 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.7083 - val_loss: 0.6516 - val_accuracy: 0.6667\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.7066 - val_loss: 0.6510 - val_accuracy: 0.6719\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.7066 - val_loss: 0.6503 - val_accuracy: 0.6771\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7083 - val_loss: 0.6496 - val_accuracy: 0.6823\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7101 - val_loss: 0.6490 - val_accuracy: 0.6823\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7083 - val_loss: 0.6483 - val_accuracy: 0.6823\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.7066 - val_loss: 0.6477 - val_accuracy: 0.6823\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7101 - val_loss: 0.6470 - val_accuracy: 0.6823\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.7101 - val_loss: 0.6464 - val_accuracy: 0.6823\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7118 - val_loss: 0.6458 - val_accuracy: 0.6823\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7101 - val_loss: 0.6451 - val_accuracy: 0.6771\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.7118 - val_loss: 0.6445 - val_accuracy: 0.6771\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7118 - val_loss: 0.6439 - val_accuracy: 0.6771\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7135 - val_loss: 0.6433 - val_accuracy: 0.6771\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7153 - val_loss: 0.6427 - val_accuracy: 0.6823\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7153 - val_loss: 0.6421 - val_accuracy: 0.6875\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7135 - val_loss: 0.6415 - val_accuracy: 0.6927\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.7135 - val_loss: 0.6409 - val_accuracy: 0.6927\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7135 - val_loss: 0.6403 - val_accuracy: 0.6927\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7118 - val_loss: 0.6397 - val_accuracy: 0.6927\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7135 - val_loss: 0.6391 - val_accuracy: 0.6927\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.7135 - val_loss: 0.6385 - val_accuracy: 0.6927\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6144 - accuracy: 0.7135 - val_loss: 0.6379 - val_accuracy: 0.6927\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.7135 - val_loss: 0.6373 - val_accuracy: 0.6927\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.7153 - val_loss: 0.6368 - val_accuracy: 0.6927\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.7153 - val_loss: 0.6362 - val_accuracy: 0.6927\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.7135 - val_loss: 0.6356 - val_accuracy: 0.6979\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6119 - accuracy: 0.7153 - val_loss: 0.6351 - val_accuracy: 0.6927\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6114 - accuracy: 0.7135 - val_loss: 0.6345 - val_accuracy: 0.6927\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 0.7135 - val_loss: 0.6339 - val_accuracy: 0.6927\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6105 - accuracy: 0.7135 - val_loss: 0.6334 - val_accuracy: 0.6927\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.7135 - val_loss: 0.6328 - val_accuracy: 0.6927\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7135 - val_loss: 0.6323 - val_accuracy: 0.6927\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6091 - accuracy: 0.7135 - val_loss: 0.6318 - val_accuracy: 0.6979\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.7135 - val_loss: 0.6312 - val_accuracy: 0.6979\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.7153 - val_loss: 0.6307 - val_accuracy: 0.7031\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7153 - val_loss: 0.6301 - val_accuracy: 0.7031\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6072 - accuracy: 0.7135 - val_loss: 0.6296 - val_accuracy: 0.7031\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6068 - accuracy: 0.7135 - val_loss: 0.6291 - val_accuracy: 0.7031\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6063 - accuracy: 0.7135 - val_loss: 0.6286 - val_accuracy: 0.7031\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.7135 - val_loss: 0.6280 - val_accuracy: 0.7031\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.7135 - val_loss: 0.6275 - val_accuracy: 0.7031\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.7135 - val_loss: 0.6270 - val_accuracy: 0.7031\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.7135 - val_loss: 0.6265 - val_accuracy: 0.7031\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6041 - accuracy: 0.7135 - val_loss: 0.6260 - val_accuracy: 0.7031\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6036 - accuracy: 0.7118 - val_loss: 0.6255 - val_accuracy: 0.7031\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.7135 - val_loss: 0.6250 - val_accuracy: 0.7031\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7118 - val_loss: 0.6245 - val_accuracy: 0.7031\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6023 - accuracy: 0.7118 - val_loss: 0.6240 - val_accuracy: 0.7083\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7118 - val_loss: 0.6235 - val_accuracy: 0.7135\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.7118 - val_loss: 0.6230 - val_accuracy: 0.7135\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7118 - val_loss: 0.6225 - val_accuracy: 0.7135\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7118 - val_loss: 0.6220 - val_accuracy: 0.7135\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7118 - val_loss: 0.6216 - val_accuracy: 0.7188\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.7118 - val_loss: 0.6211 - val_accuracy: 0.7188\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.7135 - val_loss: 0.6206 - val_accuracy: 0.7188\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7118 - val_loss: 0.6201 - val_accuracy: 0.7240\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7135 - val_loss: 0.6196 - val_accuracy: 0.7240\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.7153 - val_loss: 0.6192 - val_accuracy: 0.7240\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7153 - val_loss: 0.6187 - val_accuracy: 0.7188\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7153 - val_loss: 0.6182 - val_accuracy: 0.7188\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.7135 - val_loss: 0.6178 - val_accuracy: 0.7240\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7135 - val_loss: 0.6173 - val_accuracy: 0.7240\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7135 - val_loss: 0.6169 - val_accuracy: 0.7240\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7153 - val_loss: 0.6164 - val_accuracy: 0.7188\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.7153 - val_loss: 0.6160 - val_accuracy: 0.7188\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7153 - val_loss: 0.6155 - val_accuracy: 0.7188\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7153 - val_loss: 0.6151 - val_accuracy: 0.7188\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7153 - val_loss: 0.6146 - val_accuracy: 0.7188\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7153 - val_loss: 0.6142 - val_accuracy: 0.7188\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7153 - val_loss: 0.6138 - val_accuracy: 0.7188\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7153 - val_loss: 0.6133 - val_accuracy: 0.7188\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7153 - val_loss: 0.6129 - val_accuracy: 0.7188\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7170 - val_loss: 0.6124 - val_accuracy: 0.7188\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7170 - val_loss: 0.6120 - val_accuracy: 0.7188\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5916 - accuracy: 0.7205 - val_loss: 0.6116 - val_accuracy: 0.7188\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7240 - val_loss: 0.6111 - val_accuracy: 0.7188\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.7240 - val_loss: 0.6107 - val_accuracy: 0.7188\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7240 - val_loss: 0.6103 - val_accuracy: 0.7188\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.7240 - val_loss: 0.6099 - val_accuracy: 0.7188\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.7240 - val_loss: 0.6094 - val_accuracy: 0.7188\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7274 - val_loss: 0.6090 - val_accuracy: 0.7240\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7257 - val_loss: 0.6086 - val_accuracy: 0.7240\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7274 - val_loss: 0.6082 - val_accuracy: 0.7240\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7274 - val_loss: 0.6078 - val_accuracy: 0.7240\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7274 - val_loss: 0.6074 - val_accuracy: 0.7240\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7274 - val_loss: 0.6069 - val_accuracy: 0.7240\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7292 - val_loss: 0.6065 - val_accuracy: 0.7240\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7326 - val_loss: 0.6061 - val_accuracy: 0.7292\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7361 - val_loss: 0.6057 - val_accuracy: 0.7292\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7361 - val_loss: 0.6053 - val_accuracy: 0.7292\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7361 - val_loss: 0.6049 - val_accuracy: 0.7344\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7378 - val_loss: 0.6045 - val_accuracy: 0.7344\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7361 - val_loss: 0.6041 - val_accuracy: 0.7396\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.7361 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7361 - val_loss: 0.6033 - val_accuracy: 0.7396\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7361 - val_loss: 0.6030 - val_accuracy: 0.7396\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7344 - val_loss: 0.6026 - val_accuracy: 0.7344\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7344 - val_loss: 0.6022 - val_accuracy: 0.7396\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7344 - val_loss: 0.6018 - val_accuracy: 0.7396\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7344 - val_loss: 0.6014 - val_accuracy: 0.7396\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7361 - val_loss: 0.6010 - val_accuracy: 0.7396\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.7361 - val_loss: 0.6006 - val_accuracy: 0.7396\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.7396 - val_loss: 0.6003 - val_accuracy: 0.7396\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7396 - val_loss: 0.5999 - val_accuracy: 0.7396\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7396 - val_loss: 0.5995 - val_accuracy: 0.7396\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7396 - val_loss: 0.5992 - val_accuracy: 0.7396\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7396 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7396 - val_loss: 0.5984 - val_accuracy: 0.7344\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.7396 - val_loss: 0.5981 - val_accuracy: 0.7344\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7396 - val_loss: 0.5977 - val_accuracy: 0.7344\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7396 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7396 - val_loss: 0.5970 - val_accuracy: 0.7344\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7396 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7396 - val_loss: 0.5963 - val_accuracy: 0.7344\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7396 - val_loss: 0.5959 - val_accuracy: 0.7344\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7396 - val_loss: 0.5956 - val_accuracy: 0.7344\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7396 - val_loss: 0.5952 - val_accuracy: 0.7448\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7378 - val_loss: 0.5949 - val_accuracy: 0.7448\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7378 - val_loss: 0.5945 - val_accuracy: 0.7500\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7378 - val_loss: 0.5942 - val_accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7378 - val_loss: 0.5939 - val_accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7378 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7396 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7396 - val_loss: 0.5928 - val_accuracy: 0.7500\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7396 - val_loss: 0.5925 - val_accuracy: 0.7500\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7396 - val_loss: 0.5922 - val_accuracy: 0.7500\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7413 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7413 - val_loss: 0.5915 - val_accuracy: 0.7500\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7413 - val_loss: 0.5912 - val_accuracy: 0.7552\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7413 - val_loss: 0.5909 - val_accuracy: 0.7552\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7413 - val_loss: 0.5905 - val_accuracy: 0.7552\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7413 - val_loss: 0.5902 - val_accuracy: 0.7552\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7413 - val_loss: 0.5899 - val_accuracy: 0.7552\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7413 - val_loss: 0.5896 - val_accuracy: 0.7552\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7413 - val_loss: 0.5893 - val_accuracy: 0.7552\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7413 - val_loss: 0.5889 - val_accuracy: 0.7500\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7396 - val_loss: 0.5886 - val_accuracy: 0.7500\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7396 - val_loss: 0.5883 - val_accuracy: 0.7500\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7396 - val_loss: 0.5880 - val_accuracy: 0.7500\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7396 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.7413 - val_loss: 0.5874 - val_accuracy: 0.7448\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7431 - val_loss: 0.5871 - val_accuracy: 0.7448\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7413 - val_loss: 0.5867 - val_accuracy: 0.7448\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7413 - val_loss: 0.5864 - val_accuracy: 0.7448\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7413 - val_loss: 0.5861 - val_accuracy: 0.7448\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7396 - val_loss: 0.5858 - val_accuracy: 0.7448\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7396 - val_loss: 0.5855 - val_accuracy: 0.7448\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7413 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7413 - val_loss: 0.5849 - val_accuracy: 0.7448\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7378 - val_loss: 0.5846 - val_accuracy: 0.7448\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7378 - val_loss: 0.5843 - val_accuracy: 0.7448\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.7448\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7378 - val_loss: 0.5837 - val_accuracy: 0.7448\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5674 - accuracy: 0.7396 - val_loss: 0.5835 - val_accuracy: 0.7448\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7396 - val_loss: 0.5832 - val_accuracy: 0.7448\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7413 - val_loss: 0.5829 - val_accuracy: 0.7448\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7413 - val_loss: 0.5826 - val_accuracy: 0.7448\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7413 - val_loss: 0.5823 - val_accuracy: 0.7448\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7413 - val_loss: 0.5820 - val_accuracy: 0.7448\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7413 - val_loss: 0.5817 - val_accuracy: 0.7448\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7431 - val_loss: 0.5814 - val_accuracy: 0.7448\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7448 - val_loss: 0.5811 - val_accuracy: 0.7448\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7465 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7483 - val_loss: 0.5806 - val_accuracy: 0.7448\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7483 - val_loss: 0.5803 - val_accuracy: 0.7448\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7483 - val_loss: 0.5800 - val_accuracy: 0.7448\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5797 - val_accuracy: 0.7448\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7483 - val_loss: 0.5794 - val_accuracy: 0.7448\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7483 - val_loss: 0.5792 - val_accuracy: 0.7448\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7483 - val_loss: 0.5789 - val_accuracy: 0.7448\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5632 - accuracy: 0.7483 - val_loss: 0.5786 - val_accuracy: 0.7500\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7483 - val_loss: 0.5783 - val_accuracy: 0.7500\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5778 - val_accuracy: 0.7500\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7500 - val_loss: 0.5775 - val_accuracy: 0.7500\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7500 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5616 - accuracy: 0.7483 - val_loss: 0.5767 - val_accuracy: 0.7500\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5614 - accuracy: 0.7483 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7500 - val_loss: 0.5762 - val_accuracy: 0.7500\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5609 - accuracy: 0.7500 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.7517 - val_loss: 0.5756 - val_accuracy: 0.7500\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.7517 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7517 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7517 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7517 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7517 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5593 - accuracy: 0.7517 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.7517 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7517 - val_loss: 0.5736 - val_accuracy: 0.7500\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.7517 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5584 - accuracy: 0.7517 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7517 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7517 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.7517 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7535 - val_loss: 0.5720 - val_accuracy: 0.7552\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5573 - accuracy: 0.7552 - val_loss: 0.5718 - val_accuracy: 0.7604\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.7552 - val_loss: 0.5715 - val_accuracy: 0.7604\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7535 - val_loss: 0.5713 - val_accuracy: 0.7604\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5567 - accuracy: 0.7535 - val_loss: 0.5710 - val_accuracy: 0.7604\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5565 - accuracy: 0.7535 - val_loss: 0.5708 - val_accuracy: 0.7604\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7535 - val_loss: 0.5706 - val_accuracy: 0.7552\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7535 - val_loss: 0.5703 - val_accuracy: 0.7552\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7535 - val_loss: 0.5701 - val_accuracy: 0.7552\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7517 - val_loss: 0.5698 - val_accuracy: 0.7552\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7535 - val_loss: 0.5696 - val_accuracy: 0.7552\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7535 - val_loss: 0.5693 - val_accuracy: 0.7552\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7535 - val_loss: 0.5691 - val_accuracy: 0.7552\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7552 - val_loss: 0.5689 - val_accuracy: 0.7604\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5546 - accuracy: 0.7552 - val_loss: 0.5686 - val_accuracy: 0.7604\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7535 - val_loss: 0.5684 - val_accuracy: 0.7552\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7535 - val_loss: 0.5682 - val_accuracy: 0.7552\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7535 - val_loss: 0.5679 - val_accuracy: 0.7552\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7552 - val_loss: 0.5677 - val_accuracy: 0.7552\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7552 - val_loss: 0.5675 - val_accuracy: 0.7552\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7552 - val_loss: 0.5672 - val_accuracy: 0.7552\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5532 - accuracy: 0.7552 - val_loss: 0.5670 - val_accuracy: 0.7552\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7552 - val_loss: 0.5668 - val_accuracy: 0.7552\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7552 - val_loss: 0.5665 - val_accuracy: 0.7552\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7552 - val_loss: 0.5663 - val_accuracy: 0.7552\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7552 - val_loss: 0.5661 - val_accuracy: 0.7552\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7552 - val_loss: 0.5658 - val_accuracy: 0.7552\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.7552 - val_loss: 0.5656 - val_accuracy: 0.7552\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7552 - val_loss: 0.5654 - val_accuracy: 0.7552\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7552 - val_loss: 0.5652 - val_accuracy: 0.7552\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7552 - val_loss: 0.5649 - val_accuracy: 0.7552\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7535 - val_loss: 0.5647 - val_accuracy: 0.7552\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7535 - val_loss: 0.5645 - val_accuracy: 0.7552\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7535 - val_loss: 0.5643 - val_accuracy: 0.7552\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7552 - val_loss: 0.5641 - val_accuracy: 0.7552\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7552 - val_loss: 0.5638 - val_accuracy: 0.7552\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7552 - val_loss: 0.5636 - val_accuracy: 0.7552\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7552 - val_loss: 0.5634 - val_accuracy: 0.7552\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7552 - val_loss: 0.5632 - val_accuracy: 0.7552\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7552 - val_loss: 0.5630 - val_accuracy: 0.7552\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7552 - val_loss: 0.5627 - val_accuracy: 0.7552\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7569 - val_loss: 0.5625 - val_accuracy: 0.7552\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7587 - val_loss: 0.5623 - val_accuracy: 0.7552\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5621 - val_accuracy: 0.7552\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7622 - val_loss: 0.5619 - val_accuracy: 0.7552\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5617 - val_accuracy: 0.7552\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7622 - val_loss: 0.5615 - val_accuracy: 0.7552\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7622 - val_loss: 0.5613 - val_accuracy: 0.7552\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7622 - val_loss: 0.5610 - val_accuracy: 0.7552\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7622 - val_loss: 0.5608 - val_accuracy: 0.7604\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7604 - val_loss: 0.5606 - val_accuracy: 0.7604\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7604 - val_loss: 0.5604 - val_accuracy: 0.7604\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7622 - val_loss: 0.5602 - val_accuracy: 0.7604\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7622 - val_loss: 0.5600 - val_accuracy: 0.7604\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7639 - val_loss: 0.5598 - val_accuracy: 0.7604\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7639 - val_loss: 0.5596 - val_accuracy: 0.7604\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7639 - val_loss: 0.5594 - val_accuracy: 0.7604\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7639 - val_loss: 0.5592 - val_accuracy: 0.7604\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7639 - val_loss: 0.5590 - val_accuracy: 0.7604\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7639 - val_loss: 0.5588 - val_accuracy: 0.7552\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7639 - val_loss: 0.5586 - val_accuracy: 0.7552\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7639 - val_loss: 0.5584 - val_accuracy: 0.7552\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7639 - val_loss: 0.5582 - val_accuracy: 0.7552\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5453 - accuracy: 0.7639 - val_loss: 0.5580 - val_accuracy: 0.7552\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7639 - val_loss: 0.5578 - val_accuracy: 0.7552\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7639 - val_loss: 0.5576 - val_accuracy: 0.7552\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7639 - val_loss: 0.5574 - val_accuracy: 0.7552\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7639 - val_loss: 0.5572 - val_accuracy: 0.7552\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7639 - val_loss: 0.5570 - val_accuracy: 0.7552\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7639 - val_loss: 0.5569 - val_accuracy: 0.7552\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7639 - val_loss: 0.5567 - val_accuracy: 0.7552\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7639 - val_loss: 0.5565 - val_accuracy: 0.7552\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7639 - val_loss: 0.5563 - val_accuracy: 0.7552\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.7639 - val_loss: 0.5561 - val_accuracy: 0.7552\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7639 - val_loss: 0.5559 - val_accuracy: 0.7552\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7639 - val_loss: 0.5557 - val_accuracy: 0.7552\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7639 - val_loss: 0.5555 - val_accuracy: 0.7552\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7639 - val_loss: 0.5553 - val_accuracy: 0.7552\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7639 - val_loss: 0.5552 - val_accuracy: 0.7552\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7639 - val_loss: 0.5550 - val_accuracy: 0.7552\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7639 - val_loss: 0.5548 - val_accuracy: 0.7552\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7639 - val_loss: 0.5546 - val_accuracy: 0.7552\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7639 - val_loss: 0.5544 - val_accuracy: 0.7552\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7639 - val_loss: 0.5542 - val_accuracy: 0.7552\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7639 - val_loss: 0.5541 - val_accuracy: 0.7552\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7639 - val_loss: 0.5539 - val_accuracy: 0.7552\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7639 - val_loss: 0.5537 - val_accuracy: 0.7552\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7639 - val_loss: 0.5535 - val_accuracy: 0.7552\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7639 - val_loss: 0.5533 - val_accuracy: 0.7552\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7639 - val_loss: 0.5532 - val_accuracy: 0.7552\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7656 - val_loss: 0.5530 - val_accuracy: 0.7552\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7639 - val_loss: 0.5528 - val_accuracy: 0.7552\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7639 - val_loss: 0.5526 - val_accuracy: 0.7552\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.7622 - val_loss: 0.5525 - val_accuracy: 0.7552\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7604 - val_loss: 0.5523 - val_accuracy: 0.7552\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7604 - val_loss: 0.5521 - val_accuracy: 0.7552\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7604 - val_loss: 0.5519 - val_accuracy: 0.7552\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7604 - val_loss: 0.5518 - val_accuracy: 0.7552\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7604 - val_loss: 0.5516 - val_accuracy: 0.7552\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7604 - val_loss: 0.5514 - val_accuracy: 0.7552\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7604 - val_loss: 0.5513 - val_accuracy: 0.7552\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7604 - val_loss: 0.5511 - val_accuracy: 0.7552\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7604 - val_loss: 0.5509 - val_accuracy: 0.7552\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7604 - val_loss: 0.5508 - val_accuracy: 0.7552\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7622 - val_loss: 0.5506 - val_accuracy: 0.7552\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7622 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7622 - val_loss: 0.5503 - val_accuracy: 0.7604\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7639 - val_loss: 0.5501 - val_accuracy: 0.7604\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7639 - val_loss: 0.5499 - val_accuracy: 0.7604\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7639 - val_loss: 0.5498 - val_accuracy: 0.7604\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7639 - val_loss: 0.5496 - val_accuracy: 0.7604\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7639 - val_loss: 0.5494 - val_accuracy: 0.7604\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7639 - val_loss: 0.5493 - val_accuracy: 0.7604\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7639 - val_loss: 0.5491 - val_accuracy: 0.7604\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7639 - val_loss: 0.5489 - val_accuracy: 0.7604\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7639 - val_loss: 0.5488 - val_accuracy: 0.7604\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7656 - val_loss: 0.5486 - val_accuracy: 0.7604\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7656 - val_loss: 0.5485 - val_accuracy: 0.7604\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7656 - val_loss: 0.5483 - val_accuracy: 0.7604\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7656 - val_loss: 0.5481 - val_accuracy: 0.7604\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7674 - val_loss: 0.5480 - val_accuracy: 0.7604\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7674 - val_loss: 0.5478 - val_accuracy: 0.7604\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7674 - val_loss: 0.5477 - val_accuracy: 0.7604\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7674 - val_loss: 0.5475 - val_accuracy: 0.7604\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7674 - val_loss: 0.5474 - val_accuracy: 0.7604\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7604\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7691 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7691 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5350 - accuracy: 0.7691 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7691 - val_loss: 0.5466 - val_accuracy: 0.7604\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7691 - val_loss: 0.5464 - val_accuracy: 0.7604\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7691 - val_loss: 0.5463 - val_accuracy: 0.7604\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7691 - val_loss: 0.5461 - val_accuracy: 0.7604\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7691 - val_loss: 0.5460 - val_accuracy: 0.7604\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7691 - val_loss: 0.5458 - val_accuracy: 0.7604\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7691 - val_loss: 0.5457 - val_accuracy: 0.7604\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7691 - val_loss: 0.5455 - val_accuracy: 0.7604\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5338 - accuracy: 0.7691 - val_loss: 0.5454 - val_accuracy: 0.7604\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7604\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5335 - accuracy: 0.7674 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7691 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.7691 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7691 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7691 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7691 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7691 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7691 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7691 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7691 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7691 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7691 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7691 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7691 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7691 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7691 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7691 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7691 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7691 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7691 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7691 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7691 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7691 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7691 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7691 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7691 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7691 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7708 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7708 - val_loss: 0.5411 - val_accuracy: 0.7552\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7708 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7708 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7708 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7708 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7708 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7708 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7708 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7708 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7708 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7708 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7708 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7708 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7708 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7708 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7708 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7708 - val_loss: 0.5390 - val_accuracy: 0.7552\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7708 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7708 - val_loss: 0.5387 - val_accuracy: 0.7552\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7708 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7708 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7708 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7708 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7708 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7708 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7708 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7708 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7708 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7708 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7708 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7708 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7708 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7708 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7708 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7708 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7708 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7708 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7708 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7708 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7726 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7726 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7726 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7726 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7726 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7726 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7726 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7726 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7726 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7708 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7726 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.7708 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7708 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7708 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5232 - accuracy: 0.7708 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7708 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7708 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7708 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7708 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7708 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7708 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7708 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7691 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7691 - val_loss: 0.5333 - val_accuracy: 0.7604\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7708 - val_loss: 0.5332 - val_accuracy: 0.7604\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5219 - accuracy: 0.7708 - val_loss: 0.5331 - val_accuracy: 0.7604\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7691 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7708 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7708 - val_loss: 0.5328 - val_accuracy: 0.7604\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7708 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7708 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7708 - val_loss: 0.5325 - val_accuracy: 0.7604\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7708 - val_loss: 0.5323 - val_accuracy: 0.7604\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7708 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7708 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7708 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7708 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7708 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7708 - val_loss: 0.5317 - val_accuracy: 0.7656\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7708 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7708 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7708 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7708 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7708 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7708 - val_loss: 0.5311 - val_accuracy: 0.7656\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7708 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7708 - val_loss: 0.5309 - val_accuracy: 0.7656\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7691 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7691 - val_loss: 0.5306 - val_accuracy: 0.7656\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7691 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7691 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7691 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7691 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7691 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7691 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7691 - val_loss: 0.5299 - val_accuracy: 0.7604\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7691 - val_loss: 0.5298 - val_accuracy: 0.7604\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7691 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7708 - val_loss: 0.5296 - val_accuracy: 0.7604\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7708 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.7708 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7708 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7708 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7708 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7708 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7708 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7708 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7708 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7708 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7708 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7708 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7726 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7708 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7726 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5168 - accuracy: 0.7726 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7726 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.7726 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7726 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7726 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7726 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7726 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7726 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7726 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7726 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7726 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7726 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7726 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7726 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7726 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7726 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7726 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.7726 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7743 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7726 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7726 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7726 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5146 - accuracy: 0.7726 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7726 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7726 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7726 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7726 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7726 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7726 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7726 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7726 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7726 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7726 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7726 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7726 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7726 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7726 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7726 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7726 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7726 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7726 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7726 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7726 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7726 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7726 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7726 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7726 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7726 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7726 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7726 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7726 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7726 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7726 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7743 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7743 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7743 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7743 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7743 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7743 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7743 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7743 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7743 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7743 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7743 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7743 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7726 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7743 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7743 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7743 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7726 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7726 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7743 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7743 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7743 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7743 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7743 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7743 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7743 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.7743 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7743 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7743 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7743 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7743 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7743 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7743 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7743 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7743 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7743 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7743 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7743 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7760 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7760 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7760 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7760 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7760 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7760 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7760 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7778 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7778 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7778 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7778 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7778 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7778 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7778 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.7778 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7778 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7778 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7778 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5034 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7795 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7795 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7795 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5029 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7812 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7812 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7812 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7812 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5023 - accuracy: 0.7812 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5022 - accuracy: 0.7812 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5021 - accuracy: 0.7812 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7812 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7830 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7812 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7812 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7812 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7830 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7830 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7830 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7830 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7830 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7830 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7830 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7830 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7830 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7830 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7830 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7830 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7830 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7830 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7812 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7812 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7812 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7812 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7812 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7812 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7812 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7812 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7812 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7812 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4958 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7830 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7847 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7847 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7847 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4934 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "HTm49q2Jv7-q",
        "outputId": "b93411e7-6d64-4c1b-c7b6-8a63dbf7f789"
      },
      "id": "HTm49q2Jv7-q",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x782d177d5b70>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpret your result <br>\n",
        "\n",
        "The plot of the result is clean and shows a decreasing trend of both train and validation loss which means the model was learning from the training data and improving its predictive capability. However, I noticed that the validation loss slightly fluctuated around the later epochs which suggests a possible overfitting."
      ],
      "metadata": {
        "id": "epL41IAO5qU6"
      },
      "id": "epL41IAO5qU6"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "In this activity, we explored the training and evaluation of neural network models using different configurations. By varying the learning rates, number of epochs, and network structures, we learned how these factors impact how well the model learns and makes predictions. The graphs showing the training and validation losses helped us see when the model is getting better at learning from the data and when it might be struggling or overfitting. Overall, this activity taught us more about how neural networks work and why it's important to choose the right settings for them to work well."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}